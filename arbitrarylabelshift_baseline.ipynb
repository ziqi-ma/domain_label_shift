{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from scipy import ndimage\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1635446974111
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code modified from  https://github.com/p-lambda/gradual_domain_adaptation\n",
        "\n",
        "# helper functions\n",
        "def get_preprocessed_cifar10():\n",
        "    (train_x, train_y), (test_x, test_y) = cifar10.load_data()\n",
        "    train_x, test_x = train_x / 255.0, test_x / 255.0\n",
        "    train_x, train_y = shuffle(train_x, train_y)\n",
        "    train_y = to_categorical(train_y)\n",
        "    test_y = to_categorical(test_y)\n",
        "    #train_x = np.expand_dims(np.array(train_x), axis=-1)\n",
        "    #test_x = np.expand_dims(np.array(test_x), axis=-1)\n",
        "    return (train_x, train_y), (test_x, test_y)\n",
        "\n",
        "def continually_rotate_images(xs, start_angle, end_angle):\n",
        "    new_xs = []\n",
        "    num_points = xs.shape[0]\n",
        "    for i in range(num_points):\n",
        "        angle = float(end_angle - start_angle) / num_points * i + start_angle\n",
        "        img = ndimage.rotate(xs[i], angle, reshape=False)\n",
        "        new_xs.append(img)\n",
        "    return np.array(new_xs)\n",
        "\n",
        "def sample_rotate_images(xs, start_angle, end_angle):\n",
        "    new_xs = []\n",
        "    num_points = xs.shape[0]\n",
        "    for i in range(num_points):\n",
        "        if start_angle == end_angle:\n",
        "            angle = start_angle\n",
        "        else:\n",
        "            angle = np.random.uniform(low=start_angle, high=end_angle)\n",
        "        img = ndimage.rotate(xs[i], angle, reshape=False)\n",
        "        new_xs.append(img)\n",
        "    return np.array(new_xs)\n",
        "\n",
        "def _transition_rotation_dataset(train_x, train_y, test_x, test_y,\n",
        "                                 source_angles, target_angles, inter_func,\n",
        "                                 src_train_end, src_val_end, inter_end, target_end):\n",
        "    assert(target_end <= train_x.shape[0])\n",
        "    assert(train_x.shape[0] == train_y.shape[0])\n",
        "    src_tr_x, src_tr_y = train_x[:src_train_end], train_y[:src_train_end]\n",
        "    src_tr_x = sample_rotate_images(src_tr_x, source_angles[0], source_angles[1])\n",
        "    src_val_x, src_val_y = train_x[src_train_end:src_val_end], train_y[src_train_end:src_val_end]\n",
        "    src_val_x = sample_rotate_images(src_val_x, source_angles[0], source_angles[1])\n",
        "    tmp_inter_x, inter_y = train_x[src_val_end:inter_end], train_y[src_val_end:inter_end]\n",
        "    inter_x = inter_func(tmp_inter_x)\n",
        "    dir_inter_x = sample_rotate_images(tmp_inter_x, target_angles[0], target_angles[1])\n",
        "    dir_inter_y = np.array(inter_y)\n",
        "    # dir is the \"intermediate\" samples directly shifted to the target angles (as comparison)\n",
        "    assert(inter_x.shape == dir_inter_x.shape)\n",
        "    trg_val_x, trg_val_y = train_x[inter_end:target_end], train_y[inter_end:target_end]\n",
        "    trg_val_x = sample_rotate_images(trg_val_x, target_angles[0], target_angles[1])\n",
        "    trg_test_x, trg_test_y = test_x, test_y\n",
        "    trg_test_x = sample_rotate_images(trg_test_x, target_angles[0], target_angles[1])\n",
        "    return (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x, inter_y,\n",
        "            dir_inter_x, dir_inter_y, trg_val_x, trg_val_y, trg_test_x, trg_test_y)\n",
        "    \n",
        "\n",
        "def make_rotated_dataset(train_x, train_y, test_x, test_y,\n",
        "                         source_angles, inter_angles, target_angles,\n",
        "                         src_train_end, src_val_end, inter_end, target_end):\n",
        "    inter_func = lambda x: continually_rotate_images(x, inter_angles[0], inter_angles[1])\n",
        "    return _transition_rotation_dataset(\n",
        "        train_x, train_y, test_x, test_y, source_angles, target_angles,\n",
        "        inter_func, src_train_end, src_val_end, inter_end, target_end)\n",
        "    \n",
        "def tweak_one_shift(x, y, rho):\n",
        "    # assign class \"3\" probability rho - i started with 0 but realized that doesn't composite well w rotation...\n",
        "    # since 0 rotated is still 0...\n",
        "    # evenly distribute among the other classes\n",
        "    # y is categorical, first reverse to numerical\n",
        "    y_num = np.argmax(y, axis=1)\n",
        "    x_res_list = []\n",
        "    y_res_list = []\n",
        "    n_total = x.shape[0]\n",
        "    n_classes = 10\n",
        "    n_others = int((1-rho)*n_total/(n_classes-1))\n",
        "    n_chosen = n_total - n_others*(n_classes-1)\n",
        "    # sample from zero class\n",
        "    zero_idxs = np.argwhere(y_num == 7)[:, 0]\n",
        "    zero_chosen = np.random.choice(zero_idxs, n_chosen)\n",
        "    x_res_list.append(x[zero_chosen])\n",
        "    y_res_list.append(y[zero_chosen])\n",
        "    for i in [0,1,2,3,4,5,6,8,9]:\n",
        "        cur_idxs = np.argwhere(y_num == i)[:,0]\n",
        "        cur_selected = np.random.choice(cur_idxs, n_others)\n",
        "        x_res_list.append(x[cur_selected])\n",
        "        y_res_list.append(y[cur_selected])\n",
        "    x_res = np.concatenate(x_res_list,axis=0)\n",
        "    y_res = np.concatenate(y_res_list,axis=0)\n",
        "    # shuffle\n",
        "    shuffled_idx = np.arange(x_res.shape[0])\n",
        "    np.random.shuffle(shuffled_idx)\n",
        "    x_res_shuffled = x_res[shuffled_idx]\n",
        "    y_res_shuffled = y_res[shuffled_idx]\n",
        "    return x_res_shuffled, y_res_shuffled\n",
        "\n",
        "def resample_class_dist(x, y, p_vec): # the p_vec could be e.g. drawn from Dirichlet dist.\n",
        "    n_total = x.shape[0]\n",
        "    y_ordinal = np.argmax(y,axis=1)\n",
        "    px_counts = p_vec * n_total\n",
        "    x_res_list = []\n",
        "    y_res_list = []\n",
        "    for i in range(10):\n",
        "        cur_idxs = np.argwhere(y_ordinal == i)[:,0]\n",
        "        #print(cur_idxs)\n",
        "        if len(cur_idxs) == 0:\n",
        "            continue\n",
        "        cur_selected = np.random.choice(cur_idxs, int(px_counts[i]))\n",
        "        x_res_list.append(x[cur_selected])\n",
        "        y_res_list.append(y[cur_selected])\n",
        "    x_res = np.concatenate(x_res_list,axis=0)\n",
        "    y_res = np.concatenate(y_res_list,axis=0)\n",
        "    # shuffle\n",
        "    shuffled_idx = np.arange(x_res.shape[0])\n",
        "    np.random.shuffle(shuffled_idx)\n",
        "    x_res_shuffled = x_res[shuffled_idx]\n",
        "    y_res_shuffled = y_res[shuffled_idx]\n",
        "    return x_res_shuffled, y_res_shuffled\n",
        "\n",
        "def rotated_cifar10_60_data_func_nols():\n",
        "    (train_x, train_y), (test_x, test_y) = get_preprocessed_cifar10()\n",
        "    return make_rotated_dataset(\n",
        "        train_x, train_y, test_x, test_y, [0.0, 2.0], [2.0, 20.0], [18.0, 20.0],\n",
        "        25000, 26000, 48000, 50000)\n",
        "\n",
        "'''\n",
        "def rotated_cifar10_60_data_func_tweakone(interval, target_rho, source_rho = 0.1):\n",
        "    # interval is the granularity of label shift (change rho of shift per interval)\n",
        "    (train_x, train_y), (test_x, test_y) = get_preprocessed_cifar10()\n",
        "    (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x, inter_y,\n",
        "     dir_inter_x, dir_inter_y, trg_val_x, trg_val_y, trg_test_x, trg_test_y) = make_rotated_dataset(\n",
        "        train_x, train_y, test_x, test_y, [0.0, 2.0], [2.0, 20.0], [18.0, 20.0],\n",
        "        25000, 26000, 48000, 50000)\n",
        "    # add label shift\n",
        "    # for intermediate images we also introduce intermediate shift with granularity of interval\n",
        "    n_batches = int(inter_x.shape[0]/interval)+1\n",
        "    rho_list = np.linspace(source_rho, target_rho, n_batches)\n",
        "    inter_x_labelshifted = []\n",
        "    inter_y_labelshifted = []\n",
        "    for i in range(n_batches):\n",
        "        if (i+1)*interval <= inter_x.shape[0]:\n",
        "            cur_x = inter_x[i*interval:(i+1)*interval]\n",
        "            cur_y = inter_y[i*interval:(i+1)*interval]\n",
        "        else:\n",
        "            cur_x = inter_x[i*interval:]\n",
        "            cur_y = inter_y[i*interval:]\n",
        "        cur_shifted_x, cur_shifted_y = tweak_one_shift(cur_x, cur_y, rho_list[i])\n",
        "        inter_x_labelshifted.append(cur_shifted_x)\n",
        "        inter_y_labelshifted.append(cur_shifted_y)\n",
        "    inter_x_ls = np.concatenate(inter_x_labelshifted, axis=0)\n",
        "    inter_y_ls = np.concatenate(inter_y_labelshifted, axis=0)\n",
        "    \n",
        "    # dir_inter_x and dir_inter_y are for comparison (directly self-train on target)\n",
        "    dir_inter_x_ls, dir_inter_y_ls = tweak_one_shift(dir_inter_x, dir_inter_y, target_rho)\n",
        "\n",
        "    # shift all of trg_val_x, trg_val_y, trg_test_x, trg_test_y\n",
        "    trg_val_x_ls, trg_val_y_ls = tweak_one_shift(trg_val_x, trg_val_y, target_rho)\n",
        "    trg_test_x_ls, trg_test_y_ls = tweak_one_shift(trg_test_x, trg_test_y, target_rho)\n",
        "\n",
        "    return (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x_ls, inter_y_ls,\n",
        "            dir_inter_x_ls, dir_inter_y_ls, trg_val_x_ls, trg_val_y_ls, trg_test_x_ls, trg_test_y_ls)\n",
        "'''    \n",
        "\n",
        "def rotated_cifar10_60_data_func_dirichlet(interval, alpha, n_classes=10):\n",
        "    # interval is the granularity of x|y shift\n",
        "    # x|y shift is gradual, but each step we have arbitrary label shift\n",
        "    # return array of all dist vecs to get oracle training\n",
        "    (train_x, train_y), (test_x, test_y) = get_preprocessed_cifar10()\n",
        "    (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x, inter_y,\n",
        "     dir_inter_x, dir_inter_y, trg_val_x, trg_val_y, trg_test_x, trg_test_y) = make_rotated_dataset(\n",
        "        train_x, train_y, test_x, test_y, [0.0, 2.0], [2.0, 20.0], [18.0, 20.0],\n",
        "        25000, 26000, 48000, 50000)\n",
        "    # add label shift\n",
        "    # for intermediate images, each step introduce arbitrary shift\n",
        "    n_batches = int(inter_x.shape[0]/interval)\n",
        "    inter_x_labelshifted = []\n",
        "    inter_y_labelshifted = []\n",
        "    dist_store = np.zeros((n_batches+1, n_classes))\n",
        "    dist_store[0,:] = np.ones(n_classes)/n_classes # start with uniform\n",
        "    for i in range(n_batches):\n",
        "        cur_prob = np.random.dirichlet(np.array([alpha]*n_classes))\n",
        "        dist_store[i+1,:] = cur_prob\n",
        "        if (i+1)*interval <= inter_x.shape[0]:\n",
        "            cur_x = inter_x[i*interval:(i+1)*interval]\n",
        "            cur_y = inter_y[i*interval:(i+1)*interval]\n",
        "        else:\n",
        "            cur_x = inter_x[i*interval:]\n",
        "            cur_y = inter_y[i*interval:]\n",
        "        cur_shifted_x, cur_shifted_y = resample_class_dist(cur_x, cur_y, cur_prob)\n",
        "        inter_x_labelshifted.append(cur_shifted_x)\n",
        "        inter_y_labelshifted.append(cur_shifted_y)\n",
        "    inter_x_ls = np.concatenate(inter_x_labelshifted, axis=0)\n",
        "    inter_y_ls = np.concatenate(inter_y_labelshifted, axis=0)\n",
        "    \n",
        "    final_px = dist_store[-1,:]\n",
        "    # dir_inter_x and dir_inter_y are for comparison (directly self-train on target)\n",
        "    dir_inter_x_ls, dir_inter_y_ls = resample_class_dist(dir_inter_x, dir_inter_y, final_px)\n",
        "    \n",
        "    # shift all of trg_val_x, trg_val_y, trg_test_x, trg_test_y\n",
        "    trg_val_x_ls, trg_val_y_ls = resample_class_dist(trg_val_x, trg_val_y, final_px)\n",
        "    trg_test_x_ls, trg_test_y_ls = resample_class_dist(trg_test_x, trg_test_y, final_px)\n",
        "    return (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x_ls, inter_y_ls,\n",
        "            dir_inter_x_ls, dir_inter_y_ls, trg_val_x_ls, trg_val_y_ls, trg_test_x_ls, trg_test_y_ls, dist_store)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635446974251
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training functions\n",
        "def self_train_once(student, teacher, unsup_x, confidence_q=0.1, epochs=100, class_ws = None):\n",
        "    # Do one bootstrapping step on unsup_x, where pred_model is used to make predictions,\n",
        "    # and we use these predictions to update model.\n",
        "    logits = teacher.predict(np.concatenate([unsup_x]))\n",
        "    confidence = np.amax(logits, axis=1) - np.amin(logits, axis=1)\n",
        "    alpha = np.quantile(confidence, confidence_q)\n",
        "    indices = np.argwhere(confidence >= alpha)[:, 0]\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    preds = to_categorical(preds, num_classes=10)\n",
        "    # apply class weights\n",
        "    if class_ws is not None:\n",
        "        # get class ws dict\n",
        "        cw = {}\n",
        "        for i in range(10):\n",
        "            cw[i] = class_ws[i]\n",
        "        student.fit(unsup_x[indices], preds[indices], epochs=epochs, class_weight = cw, verbose=False)\n",
        "    else:\n",
        "        student.fit(unsup_x[indices], preds[indices], epochs=epochs, verbose=False)\n",
        "\n",
        "def soft_self_train_once(student, teacher, unsup_x, epochs=100):\n",
        "    probs = teacher.predict(np.concatenate([unsup_x]))\n",
        "    student.fit(unsup_x, probs, epochs=epochs, verbose=False)\n",
        "\n",
        "def self_train(teacher, unsup_x, confidence_q=0.1, epochs=100, repeats=1,\n",
        "               target_x=None, target_y=None, soft=False):\n",
        "    accuracies = []\n",
        "    student = teacher\n",
        "    for i in range(repeats):\n",
        "        if soft:\n",
        "            soft_self_train_once(student, teacher, unsup_x, epochs)\n",
        "        else:\n",
        "            self_train_once(student, teacher, unsup_x, confidence_q, epochs)\n",
        "        if target_x is not None and target_y is not None:\n",
        "            _, accuracy = student.evaluate(target_x, target_y, verbose=True)\n",
        "            accuracies.append(accuracy)\n",
        "        teacher = student\n",
        "    return accuracies, student\n",
        "\n",
        "def gradual_self_train(teacher, unsup_x, debug_y, interval, confidence_q=0.1,\n",
        "                       epochs=100, soft=False):\n",
        "    upper_idx = int(unsup_x.shape[0] / interval)\n",
        "    accuracies = []\n",
        "    student = teacher\n",
        "    for i in range(upper_idx):\n",
        "        cur_xs = unsup_x[interval*i:interval*(i+1)]\n",
        "        cur_ys = debug_y[interval*i:interval*(i+1)]\n",
        "        # _, student = self_train(\n",
        "        #     student_func, teacher, unsup_x, confidence_q, epochs, repeats=2)\n",
        "        if soft:\n",
        "            soft_self_train_once(student, teacher, cur_xs, epochs)\n",
        "        else:\n",
        "            self_train_once(student, teacher, cur_xs, confidence_q, epochs)\n",
        "        _, accuracy = student.evaluate(cur_xs, cur_ys)\n",
        "        accuracies.append(accuracy)\n",
        "        teacher = student\n",
        "    return accuracies, student\n",
        "\n",
        "def gradual_corrected_self_train(teacher, unsup_x, debug_y, interval, dist_store, confidence_q=0.1,\n",
        "                       epochs=100, soft=False):\n",
        "    upper_idx = int(unsup_x.shape[0] / interval)\n",
        "    accuracies = []\n",
        "    student = teacher\n",
        "    for i in range(upper_idx):\n",
        "        cur_xs = unsup_x[interval*i:interval*(i+1)]\n",
        "        cur_ys = debug_y[interval*i:interval*(i+1)]\n",
        "       \n",
        "        # weight by distance store\n",
        "        class_ws = dist_store[i+1,:]/dist_store[i,:]\n",
        "        # normalize\n",
        "        class_ws = class_ws / np.mean(class_ws)\n",
        "        \n",
        "        if soft:\n",
        "            soft_self_train_once(student, teacher, cur_xs, epochs)\n",
        "        else:\n",
        "            self_train_once(student, teacher, cur_xs, confidence_q, epochs, class_ws=class_ws)\n",
        "        _, accuracy = student.evaluate(cur_xs, cur_ys)\n",
        "        accuracies.append(accuracy)\n",
        "        teacher = student\n",
        "    return accuracies, student"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635446974651
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "def simple_softmax_conv_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(10, activation='softmax')) \n",
        "    # compile model\n",
        "    \n",
        "    model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635446975205
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rand_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "def shuffle(xs, ys):\n",
        "    indices = list(range(len(xs)))\n",
        "    np.random.shuffle(indices)\n",
        "    return xs[indices], ys[indices]"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635446975398
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exp(seed, label_shift, tweak_one_rho = None, dirichlet_alpha = None, interval=2000, epochs=100, conf_q=0.1, n_classes=10):\n",
        "    # get data\n",
        "    if label_shift == \"NO_LS\":\n",
        "        (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x, inter_y, dir_inter_x, dir_inter_y,\n",
        "         trg_eval_x, trg_eval_y, trg_test_x, trg_test_y) = rotated_cifar10_60_data_func_nols()\n",
        "        n_batches = int(inter_x.shape[0]/interval)\n",
        "        dist_store = np.ones((n_batches+1, n_classes))\n",
        "    elif label_shift == \"TWEAK_ONE\":\n",
        "        if tweak_one_rho is None:\n",
        "            print(\"no tweak one rho!\")\n",
        "            return\n",
        "        (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x, inter_y, dir_inter_x, dir_inter_y,\n",
        "         trg_eval_x, trg_eval_y, trg_test_x, trg_test_y) = rotated_cifar10_60_data_func_tweakone(interval, tweak_one_rho)\n",
        "    elif label_shift == \"DIRICHLET\":\n",
        "        if dirichlet_alpha is None:\n",
        "            print(\"no dirichlet alpha!\")\n",
        "            return\n",
        "        (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x, inter_y, dir_inter_x, dir_inter_y,\n",
        "         trg_eval_x, trg_eval_y, trg_test_x, trg_test_y, diststore) = rotated_cifar10_60_data_func_dirichlet(interval, dirichlet_alpha)\n",
        "        \n",
        "        print(diststore)\n",
        "    # set seed\n",
        "    rand_seed(seed)\n",
        "\n",
        "    # Train source model\n",
        "    source_model = simple_softmax_conv_model()\n",
        "    source_model.fit(src_tr_x, src_tr_y, epochs=epochs, verbose=False)\n",
        "    _, src_acc = source_model.evaluate(src_val_x, src_val_y)\n",
        "    _, srcmodel_acc = source_model.evaluate(trg_eval_x, trg_eval_y)\n",
        "\n",
        "    \n",
        "    # Train directly on target (oracle)\n",
        "    print(\"\\n\\n Direct train on target:\")\n",
        "    target_model = simple_softmax_conv_model()\n",
        "    target_model.fit(dir_inter_x, dir_inter_y, epochs=epochs, verbose=False)\n",
        "    _, oracle_target_acc = target_model.evaluate(trg_eval_x, trg_eval_y)\n",
        "    \n",
        "    # comment this out bc we already know it's bad\n",
        "    '''\n",
        "    # self training on target (bad baseline)\n",
        "    NUM_REPEATS = 1 # they repeat more in the paper, but small difference\n",
        "    print(\"\\n\\n Direct self train on target:\")\n",
        "    teacher = simple_softmax_conv_model()\n",
        "    teacher.set_weights(source_model.get_weights())\n",
        "    target_accuracies, _ = self_train(teacher, dir_inter_x, epochs=epochs, target_x=trg_eval_x,\n",
        "            target_y=trg_eval_y, repeats=NUM_REPEATS, confidence_q=conf_q)\n",
        "    '''\n",
        "    # Gradual self-training (paper baseline)\n",
        "    print(\"\\n\\n Gradual self-training:\")\n",
        "    teacher = simple_softmax_conv_model()\n",
        "    teacher.set_weights(source_model.get_weights())\n",
        "    gradual_accuracies, student = gradual_self_train(teacher, inter_x, inter_y, interval, epochs=epochs,\n",
        "            confidence_q=conf_q)\n",
        "    _, acc = student.evaluate(trg_eval_x, trg_eval_y)\n",
        "    gradual_accuracies.append(acc)\n",
        "    \n",
        "    # corrected gradual self training (assuming we know label shift)\n",
        "    print(\"\\n\\n Gradual corrected self-training:\")\n",
        "    teacher = simple_softmax_conv_model()\n",
        "    teacher.set_weights(source_model.get_weights())\n",
        "    gradual_corrected_accuracies, student = gradual_corrected_self_train(teacher, inter_x, inter_y, interval, diststore, epochs=epochs,\n",
        "            confidence_q=conf_q)\n",
        "    _, acc = student.evaluate(trg_eval_x, trg_eval_y)\n",
        "    gradual_corrected_accuracies.append(acc)\n",
        "    \n",
        "\n",
        "    print(f\"Source model acc on target: {srcmodel_acc}\")\n",
        "    #print(f\"direct self train on target: {target_accuracies[-1]}\")\n",
        "    print(f\"gradual self training accuracies: {gradual_accuracies[-1]}\")\n",
        "    print(f\"gradual labelshift corrected self training accuracies: {gradual_corrected_accuracies[-1]}\")\n",
        "    print(f\"oracle accuracy: {oracle_target_acc}\")\n",
        "    return np.array([srcmodel_acc, gradual_accuracies[-1], gradual_corrected_accuracies[-1], oracle_target_acc]), diststore"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635468400640
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exp_dirichlet(seed):\n",
        "    alpha = 1\n",
        "    res, diststore = exp(seed, \"DIRICHLET\", dirichlet_alpha=alpha)\n",
        "    return res, diststore\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635446976015
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_nols, diststore_nols = exp(1, \"NO_LS\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "32/32 [==============================] - 1s 19ms/step - loss: 0.4669 - accuracy: 0.8640\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 1.0100 - accuracy: 0.7170\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Direct train on target:\n63/63 [==============================] - 2s 20ms/step - loss: 0.6334 - accuracy: 0.8155\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual self-training:\n63/63 [==============================] - 2s 20ms/step - loss: 1.7043 - accuracy: 0.8330\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 2.3254 - accuracy: 0.7850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 2.8125 - accuracy: 0.7545\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 3.4019 - accuracy: 0.7150\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 18ms/step - loss: 3.8034 - accuracy: 0.6995\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 3.9803 - accuracy: 0.6760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 4.4854 - accuracy: 0.6640\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 4.6042 - accuracy: 0.6415\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 25ms/step - loss: 5.3739 - accuracy: 0.6005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 5.6895 - accuracy: 0.5830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 4.3368 - accuracy: 0.5760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual corrected self-training:\n"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'diststore' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ded642d25638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres_nols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiststore_nols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NO_LS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-9c0b4ecf74d6>\u001b[0m in \u001b[0;36mexp\u001b[0;34m(seed, label_shift, tweak_one_rho, dirichlet_alpha, interval, epochs, conf_q, n_classes)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mteacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_softmax_conv_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     gradual_corrected_accuracies, student = gradual_corrected_self_train(teacher, inter_x, inter_y, interval, diststore, epochs=epochs,\n\u001b[0m\u001b[1;32m     62\u001b[0m             confidence_q=conf_q)\n\u001b[1;32m     63\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_eval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_eval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'diststore' referenced before assignment"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = np.zeros((10,5,4))\n",
        "outres = open(\"res.txt\", \"ab\")\n",
        "shifts = open(\"distr.txt\", \"ab\")\n",
        "for seed in range(10):\n",
        "    res, diststore = exp_dirichlet(seed)\n",
        "    np.savetxt(outres, res)\n",
        "    np.savetxt(shifts, diststore)\n",
        "    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RESULTS\n",
        "# no label shift exp\n",
        "train on src, eval on target: 0.717\n",
        "gradual self training accuracy: 0.576\n",
        "oracle accuracy: 0.815\n",
        "\n",
        "# alpha=1 exps\n",
        "# repeat 0\n",
        "train on src, eval on target: 0.6760280728340149\n",
        "gradual self training accuracy: 0.38766297698020935\n",
        "gradual labelshift corrected self training accuracy: 0.27733200788497925\n",
        "oracle (train on target) accuracy: 0.7938816547393799\n",
        "# repeat 1\n",
        "train on src, eval on target: 0.6609829664230347\n",
        "gradual self training accuracy: 0.3154463469982147\n",
        "gradual labelshift corrected self training accuracy: 0.27482447028160095\n",
        "oracle accuracy: 0.8159478306770325\n",
        "# repeat 2\n",
        "train on src, eval on target: 0.6508015990257263\n",
        "gradual self training accuracy: 0.2374749481678009\n",
        "gradual labelshift corrected self training accuracy: 0.18286573886871338\n",
        "oracle accuracy: 0.7990981936454773\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = np.array([[0.6760280728340149,0.38766297698020935,0.27733200788497925,0.7938816547393799],\n",
        "[0.6609829664230347,0.3154463469982147,0.27482447028160095,0.8159478306770325],\n",
        "[0.6508015990257263,0.2374749481678009,0.18286573886871338,0.7990981936454773]])\n",
        "avgs = np.mean(res, axis=0)\n",
        "stds = np.std(res, axis=0)\n",
        "print(\"src model, self train, self train corrected, oracle\")\n",
        "print(f\"avg: {avgs}\")\n",
        "print(f\"std: {stds}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "src model, self train, self train corrected, oracle\navg: [0.66260421 0.31352809 0.24500741 0.80297589]\nstd: [0.01036227 0.06132901 0.04395272 0.00941653]\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635488802278
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logs\n",
        "alpha=1\n",
        "[[1.00000000e-01 1.00000000e-01 1.00000000e-01 1.00000000e-01\n",
        "  1.00000000e-01 1.00000000e-01 1.00000000e-01 1.00000000e-01\n",
        "  1.00000000e-01 1.00000000e-01]\n",
        " [5.98460406e-02 2.06062929e-02 1.47128830e-01 5.35340629e-02\n",
        "  3.69837384e-01 1.98609164e-01 1.87344720e-03 1.85135918e-02\n",
        "  1.20694752e-01 9.35643334e-03]\n",
        " [9.86610231e-02 1.20809247e-01 1.02357901e-01 2.32138436e-02\n",
        "  6.62202892e-03 1.04673658e-01 6.14302528e-02 7.34079179e-02\n",
        "  4.93948312e-02 3.59429296e-01]\n",
        " [1.80272907e-02 3.38710834e-01 5.74091022e-02 2.14189091e-04\n",
        "  2.76154233e-02 1.78721573e-02 5.10846860e-01 3.79673791e-03\n",
        "  1.66561532e-02 8.85125138e-03]\n",
        " [3.19076616e-02 7.78511644e-02 8.60216457e-02 1.84547842e-01\n",
        "  6.12788883e-05 6.67306143e-02 1.22249504e-01 2.74718568e-01\n",
        "  1.43962712e-01 1.19490093e-02]\n",
        " [2.33818945e-03 8.76027612e-03 1.42729179e-01 4.44581232e-02\n",
        "  5.13748578e-02 3.69529137e-01 8.82811146e-03 2.20682911e-01\n",
        "  1.28443714e-01 2.28555014e-02]\n",
        " [3.70396315e-02 4.27193733e-02 2.98753893e-02 9.55501092e-02\n",
        "  3.61968121e-01 1.50798260e-01 1.32115036e-01 3.65379206e-02\n",
        "  1.09194466e-01 4.20169267e-03]\n",
        " [3.82825216e-02 3.47015664e-02 1.04605034e-02 3.70738473e-02\n",
        "  2.35967850e-03 2.77359551e-01 1.00891389e-01 1.86744056e-01\n",
        "  6.03188698e-02 2.51808018e-01]\n",
        " [1.36778149e-02 2.75106614e-01 9.48697287e-04 1.31748925e-01\n",
        "  1.92103751e-01 4.26160007e-02 1.49877041e-01 7.92831861e-03\n",
        "  1.69095181e-01 1.68976566e-02]\n",
        " [1.47463733e-01 4.07800109e-01 5.19735731e-02 4.90014734e-02\n",
        "  4.65121983e-02 9.97861321e-02 1.31003315e-02 6.68285093e-02\n",
        "  5.99581655e-02 5.75757749e-02]\n",
        " [8.70900148e-03 1.20176504e-01 3.51113682e-01 8.74317348e-02\n",
        "  5.93625339e-02 6.01045512e-02 5.18997947e-02 2.04643032e-01\n",
        "  1.95399615e-02 3.70192042e-02]\n",
        " [1.11995580e-01 2.83017458e-03 9.53220545e-02 3.07614750e-01\n",
        "  1.43156039e-01 2.77195814e-03 2.34853268e-01 2.92612777e-02\n",
        "  3.03103352e-02 4.18845632e-02]]\n",
        "32/32 [==============================] - 1s 21ms/step - loss: 0.5214 - accuracy: 0.847\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 1.1510 - accuracy: 0.676\n",
        "\n",
        "\n",
        " Gradual corrected self-training:\n",
        "63/63 [==============================] - 2s 21ms/step - loss: 1.8416 - accuracy: 0.831\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 1.5860 - accuracy: 0.802\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 2.3855 - accuracy: 0.757\n",
        "63/63 [==============================] - 2s 27ms/step - loss: 2.8376 - accuracy: 0.656\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 2.3238 - accuracy: 0.751\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 4.9589 - accuracy: 0.514\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 3.4249 - accuracy: 0.691\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 4.6846 - accuracy: 0.586\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 4.9627 - accuracy: 0.620\n",
        "63/63 [==============================] - 2s 28ms/step - loss: 9.8471 - accuracy: 0.394\n",
        "63/63 [==============================] - 2s 28ms/step - loss: 10.8150 - accuracy: 0.27\n",
        "\n",
        "\n",
        " Direct train on target:\n",
        "63/63 [==============================] - 2s 21ms/step - loss: 0.9522 - accuracy: 0.793\n",
        "\n",
        "\n",
        " Gradual self-training:\n",
        "63/63 [==============================] - 2s 21ms/step - loss: 2.4417 - accuracy: 0.817\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 3.1940 - accuracy: 0.789\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 2.9124 - accuracy: 0.815\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 6.9415 - accuracy: 0.552\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 8.8265 - accuracy: 0.505\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 7.0799 - accuracy: 0.568\n",
        "63/63 [==============================] - 2s 26ms/step - loss: 8.4447 - accuracy: 0.467\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 5.9749 - accuracy: 0.642\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 7.4782 - accuracy: 0.539\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 9.0148 - accuracy: 0.434\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 10.1633 - accuracy: 0.38\n",
        "Source model acc on target: 0.6760280728340149\n",
        "gradual self training accuracies: 0.38766297698020935\n",
        "gradual labelshift corrected self training accuracies: 0.27733200788497925\n",
        "oracle accuracy: 0.7938816547393799\n",
        "[[1.00000000e-01 1.00000000e-01 1.00000000e-01 1.00000000e-01\n",
        "  1.00000000e-01 1.00000000e-01 1.00000000e-01 1.00000000e-01\n",
        "  1.00000000e-01 1.00000000e-01]\n",
        " [5.98460406e-02 2.06062929e-02 1.47128830e-01 5.35340629e-02\n",
        "  3.69837384e-01 1.98609164e-01 1.87344720e-03 1.85135918e-02\n",
        "  1.20694752e-01 9.35643334e-03]\n",
        " [9.86610231e-02 1.20809247e-01 1.02357901e-01 2.32138436e-02\n",
        "  6.62202892e-03 1.04673658e-01 6.14302528e-02 7.34079179e-02\n",
        "  4.93948312e-02 3.59429296e-01]\n",
        " [1.80272907e-02 3.38710834e-01 5.74091022e-02 2.14189091e-04\n",
        "  2.76154233e-02 1.78721573e-02 5.10846860e-01 3.79673791e-03\n",
        "  1.66561532e-02 8.85125138e-03]\n",
        " [3.19076616e-02 7.78511644e-02 8.60216457e-02 1.84547842e-01\n",
        "  6.12788883e-05 6.67306143e-02 1.22249504e-01 2.74718568e-01\n",
        "  1.43962712e-01 1.19490093e-02]\n",
        " [2.33818945e-03 8.76027612e-03 1.42729179e-01 4.44581232e-02\n",
        "  5.13748578e-02 3.69529137e-01 8.82811146e-03 2.20682911e-01\n",
        "  1.28443714e-01 2.28555014e-02]\n",
        " [3.70396315e-02 4.27193733e-02 2.98753893e-02 9.55501092e-02\n",
        "  3.61968121e-01 1.50798260e-01 1.32115036e-01 3.65379206e-02\n",
        "  1.09194466e-01 4.20169267e-03]\n",
        " [3.82825216e-02 3.47015664e-02 1.04605034e-02 3.70738473e-02\n",
        "  2.35967850e-03 2.77359551e-01 1.00891389e-01 1.86744056e-01\n",
        "  6.03188698e-02 2.51808018e-01]\n",
        " [1.36778149e-02 2.75106614e-01 9.48697287e-04 1.31748925e-01\n",
        "  1.92103751e-01 4.26160007e-02 1.49877041e-01 7.92831861e-03\n",
        "  1.69095181e-01 1.68976566e-02]\n",
        " [1.47463733e-01 4.07800109e-01 5.19735731e-02 4.90014734e-02\n",
        "  4.65121983e-02 9.97861321e-02 1.31003315e-02 6.68285093e-02\n",
        "  5.99581655e-02 5.75757749e-02]\n",
        " [8.70900148e-03 1.20176504e-01 3.51113682e-01 8.74317348e-02\n",
        "  5.93625339e-02 6.01045512e-02 5.18997947e-02 2.04643032e-01\n",
        "  1.95399615e-02 3.70192042e-02]\n",
        " [1.11995580e-01 2.83017458e-03 9.53220545e-02 3.07614750e-01\n",
        "  1.43156039e-01 2.77195814e-03 2.34853268e-01 2.92612777e-02\n",
        "  3.03103352e-02 4.18845632e-02]]\n",
        "32/32 [==============================] - 1s 21ms/step - loss: 0.5346 - accuracy: 0.848\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 1.1610 - accuracy: 0.661\n",
        "\n",
        "\n",
        " Gradual corrected self-training:\n",
        "63/63 [==============================] - 2s 22ms/step - loss: 2.0265 - accuracy: 0.804\n",
        "63/63 [==============================] - 2s 28ms/step - loss: 1.4233 - accuracy: 0.826\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 0.9952 - accuracy: 0.875\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 4.5037 - accuracy: 0.515\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 3.3959 - accuracy: 0.523\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 7.8660 - accuracy: 0.439\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 7.0080 - accuracy: 0.453\n",
        "63/63 [==============================] - 2s 27ms/step - loss: 7.3015 - accuracy: 0.540\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 6.0705 - accuracy: 0.488\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 13.8238 - accuracy: 0.26\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 14.5816 - accuracy: 0.27\n",
        "\n",
        "\n",
        " Direct train on target:\n",
        "63/63 [==============================] - 1s 20ms/step - loss: 0.8018 - accuracy: 0.815\n",
        "\n",
        "\n",
        " Gradual self-training:\n",
        "63/63 [==============================] - 2s 21ms/step - loss: 3.0676 - accuracy: 0.779\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 2.4622 - accuracy: 0.825\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 2.3713 - accuracy: 0.827\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 6.5385 - accuracy: 0.584\n",
        "63/63 [==============================] - 2s 28ms/step - loss: 7.7225 - accuracy: 0.473\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 7.7483 - accuracy: 0.499\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 6.5339 - accuracy: 0.552\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 7.1077 - accuracy: 0.587\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 8.7359 - accuracy: 0.499\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 13.6623 - accuracy: 0.27\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 12.9987 - accuracy: 0.31\n",
        "Source model acc on target: 0.6609829664230347\n",
        "gradual self training accuracies: 0.3154463469982147\n",
        "gradual labelshift corrected self training accuracies: 0.27482447028160095\n",
        "oracle accuracy: 0.8159478306770325\n",
        "[[0.1        0.1        0.1        0.1        0.1        0.1\n",
        "  0.1        0.1        0.1        0.1       ]\n",
        " [0.00920846 0.10519726 0.24446268 0.21915013 0.078105   0.10100306\n",
        "  0.11307841 0.08177611 0.03402342 0.01399547]\n",
        " [0.11388653 0.04699108 0.10161898 0.00663361 0.18645427 0.02723764\n",
        "  0.29198539 0.06954231 0.07508158 0.08056861]\n",
        " [0.09438969 0.0538275  0.09765329 0.11742985 0.14192956 0.37562173\n",
        "  0.05074547 0.05286978 0.01133437 0.00419877]\n",
        " [0.05876256 0.05096457 0.35305816 0.06115281 0.04001653 0.14005111\n",
        "  0.05543155 0.03367892 0.1898005  0.01708329]\n",
        " [0.21238748 0.23761127 0.0420231  0.01490568 0.10287508 0.0617557\n",
        "  0.15575657 0.0042202  0.06935607 0.09910885]\n",
        " [0.11334969 0.18783714 0.07462556 0.01514986 0.02015026 0.01485546\n",
        "  0.20029082 0.04120549 0.09357309 0.23896264]\n",
        " [0.03895728 0.01025825 0.08367702 0.09148604 0.08526358 0.03415651\n",
        "  0.29143287 0.08852153 0.25552561 0.02072131]\n",
        " [0.06583194 0.09082959 0.07238788 0.00119135 0.06649471 0.31316225\n",
        "  0.16053588 0.13419333 0.05980999 0.03556308]\n",
        " [0.22319705 0.00404535 0.11741573 0.45527205 0.03985211 0.00234375\n",
        "  0.03558894 0.00746535 0.07005122 0.04476847]\n",
        " [0.03260773 0.22077345 0.20031461 0.06485537 0.01845554 0.21781631\n",
        "  0.13970526 0.09724501 0.00261607 0.00561064]\n",
        " [0.09363265 0.03212249 0.18023477 0.18799683 0.02432023 0.04011434\n",
        "  0.09911122 0.01513478 0.09459257 0.23274011]]\n",
        "32/32 [==============================] - 1s 27ms/step - loss: 0.4523 - accuracy: 0.872\n",
        "63/63 [==============================] - 2s 27ms/step - loss: 1.2220 - accuracy: 0.650\n",
        "\n",
        "\n",
        " Gradual corrected self-training:\n",
        "63/63 [==============================] - 2s 21ms/step - loss: 2.5289 - accuracy: 0.788\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 1.8929 - accuracy: 0.811\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 2.9649 - accuracy: 0.684\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 4.2602 - accuracy: 0.621\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 3.5444 - accuracy: 0.702\n",
        "63/63 [==============================] - 2s 28ms/step - loss: 4.0961 - accuracy: 0.663\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 5.2019 - accuracy: 0.589\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 6.0464 - accuracy: 0.494\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 10.5697 - accuracy: 0.22\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 7.5025 - accuracy: 0.392\n",
        "63/63 [==============================] - 1s 20ms/step - loss: 9.4568 - accuracy: 0.182\n",
        "\n",
        "\n",
        " Direct train on target:\n",
        "63/63 [==============================] - 2s 21ms/step - loss: 0.8239 - accuracy: 0.799\n",
        "\n",
        "\n",
        " Gradual self-training:\n",
        "63/63 [==============================] - 2s 21ms/step - loss: 2.6489 - accuracy: 0.793\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 2.2170 - accuracy: 0.822\n",
        "63/63 [==============================] - 2s 27ms/step - loss: 4.5735 - accuracy: 0.693\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 5.7156 - accuracy: 0.611\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 4.8029 - accuracy: 0.663\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 4.9801 - accuracy: 0.666\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 5.4112 - accuracy: 0.628\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 7.2780 - accuracy: 0.522\n",
        "63/63 [==============================] - 2s 27ms/step - loss: 16.8916 - accuracy: 0.21\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 11.3129 - accuracy: 0.35\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 12.6241 - accuracy: 0.23\n",
        "Source model acc on target: 0.6508015990257263\n",
        "gradual self training accuracies: 0.2374749481678009\n",
        "gradual labelshift corrected self training accuracies: 0.18286573886871338\n",
        "oracle accuracy: 0.7990981936454773\n",
        "[[0.1        0.1        0.1        0.1        0.1        0.1\n",
        "  0.1        0.1        0.1        0.1       ]\n",
        " [0.43426777 0.02548648 0.09784025 0.01016087 0.20347776 0.03905409\n",
        "  0.07151477 0.0679321  0.01984771 0.03041821]\n",
        " [0.0152778  0.14329793 0.00777125 0.03368301 0.10856033 0.00424655\n",
        "  0.07217006 0.24334717 0.0955263  0.27611961]\n",
        " [0.17644353 0.0071628  0.06353623 0.2734867  0.1323496  0.09032544\n",
        "  0.0523811  0.09483121 0.1066804  0.002803  ]\n",
        " [0.08267022 0.01389437 0.12645167 0.10969503 0.03590553 0.10142308\n",
        "  0.00588439 0.12409575 0.28276259 0.11721737]\n",
        " [0.07732292 0.03154491 0.20944527 0.0278611  0.05623777 0.24802172\n",
        "  0.05195967 0.02086557 0.00774858 0.26899249]\n",
        " [0.05740667 0.03426496 0.03311653 0.02752302 0.08898477 0.12038785\n",
        "  0.09554451 0.12947775 0.39384525 0.01944869]\n",
        " [0.00942974 0.01730401 0.01941036 0.06065468 0.09207203 0.08145116\n",
        "  0.45367087 0.16969496 0.08213811 0.01417409]\n",
        " [0.10205719 0.01482108 0.01716312 0.23214785 0.20865439 0.01085493\n",
        "  0.08700781 0.14193612 0.02780943 0.15754809]\n",
        " [0.04531372 0.00384367 0.09939776 0.15298637 0.07508423 0.00904435\n",
        "  0.3178818  0.2561961  0.01719192 0.02306008]\n",
        " [0.01782723 0.29889221 0.09204134 0.20569379 0.02600816 0.05225984\n",
        "  0.21971785 0.02382796 0.01250112 0.0512305 ]\n",
        " [0.10189782 0.34439464 0.08150505 0.13021925 0.01294888 0.1704595\n",
        "  0.05289639 0.07382536 0.03124227 0.00061085]]\n",
        "32/32 [==============================] - 1s 21ms/step - loss: 0.5191 - accuracy: 0.847\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 0.8420 - accuracy: 0.741\n",
        "\n",
        "\n",
        " Gradual corrected self-training:\n",
        "63/63 [==============================] - 2s 21ms/step - loss: 1.4267 - accuracy: 0.859\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 1.3612 - accuracy: 0.851\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 4.7195 - accuracy: 0.590\n",
        "63/63 [==============================] - 2s 27ms/step - loss: 3.3099 - accuracy: 0.669\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "alpha=3\n",
        "[[0.1        0.1        0.1        0.1        0.1        0.1\n",
        "  0.1        0.1        0.1        0.1       ]\n",
        " [0.02809297 0.11630723 0.079684   0.09803938 0.06429211 0.20740738\n",
        "  0.16656009 0.09682844 0.06031113 0.08247726]\n",
        " [0.14636088 0.05364192 0.0581611  0.14510109 0.13515942 0.10033193\n",
        "  0.06023741 0.08604272 0.12840842 0.08655511]\n",
        " [0.07998439 0.10002483 0.08033415 0.02605783 0.18004121 0.07131745\n",
        "  0.15897384 0.14379974 0.13303226 0.0264343 ]\n",
        " [0.13353901 0.16185091 0.20553315 0.02925504 0.08088792 0.09193798\n",
        "  0.11582048 0.09803076 0.05782158 0.02532317]\n",
        " [0.11115675 0.07574319 0.05471012 0.05691571 0.09436329 0.06984626\n",
        "  0.13592566 0.16245463 0.17389904 0.06498535]\n",
        " [0.08618071 0.089992   0.08721382 0.1233224  0.16014676 0.0300626\n",
        "  0.04865356 0.22582798 0.10337167 0.04522848]\n",
        " [0.12864227 0.01756888 0.13742367 0.04799097 0.00981324 0.10305676\n",
        "  0.11804083 0.04609315 0.17034157 0.22102867]\n",
        " [0.07775026 0.08925943 0.13735609 0.12302603 0.15207733 0.12242215\n",
        "  0.1251899  0.06114255 0.07740277 0.0343735 ]\n",
        " [0.19202908 0.04221039 0.12593194 0.08826102 0.03880874 0.08354088\n",
        "  0.05505991 0.01333604 0.22638142 0.13444059]\n",
        " [0.0115246  0.08844235 0.0929364  0.19397308 0.09905786 0.06596863\n",
        "  0.18586824 0.08572838 0.13763662 0.03886385]\n",
        " [0.04224256 0.03963463 0.15308756 0.12695038 0.13388806 0.13203123\n",
        "  0.09750165 0.13342107 0.03792463 0.10331823]]\n",
        "32/32 [==============================] - 1s 21ms/step - loss: 0.5214 - accuracy: 0.847\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 1.0489 - accuracy: 0.701\n",
        "\n",
        "\n",
        " Gradual corrected self-training:\n",
        "63/63 [==============================] - 2s 22ms/step - loss: 1.8831 - accuracy: 0.846\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 3.2008 - accuracy: 0.754\n",
        "63/63 [==============================] - 2s 27ms/step - loss: 2.8710 - accuracy: 0.755\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 4.6116 - accuracy: 0.684\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 3.9486 - accuracy: 0.696\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 5.6769 - accuracy: 0.610\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 4.2194 - accuracy: 0.683\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 6.1129 - accuracy: 0.569\n",
        "63/63 [==============================] - 2s 27ms/step - loss: 5.0134 - accuracy: 0.663\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 7.9898 - accuracy: 0.532\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 6.2962 - accuracy: 0.483\n",
        "\n",
        "\n",
        " Direct train on target:\n",
        "63/63 [==============================] - 2s 22ms/step - loss: 0.9526 - accuracy: 0.768\n",
        "\n",
        "\n",
        " Gradual self-training:\n",
        "63/63 [==============================] - 2s 21ms/step - loss: 1.9425 - accuracy: 0.839\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 3.2295 - accuracy: 0.765\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 2.9066 - accuracy: 0.781\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 3.7881 - accuracy: 0.727\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 3.7017 - accuracy: 0.740\n",
        "63/63 [==============================] - 2s 27ms/step - loss: 5.1212 - accuracy: 0.674\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 4.9778 - accuracy: 0.677\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 6.7238 - accuracy: 0.581\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 5.7740 - accuracy: 0.628\n",
        "63/63 [==============================] - 1s 22ms/step - loss: 7.3486 - accuracy: 0.568\n",
        "63/63 [==============================] - 1s 21ms/step - loss: 5.0898 - accuracy: 0.543\n",
        "Source model acc on target: 0.7017543911933899\n",
        "gradual self training accuracies: 0.5438596606254578\n",
        "gradual labelshift corrected self training accuracies: 0.48370927572250366\n",
        "oracle accuracy: 0.7684210538864136"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "azureml_py38_tensorflow",
      "language": "python",
      "display_name": "Python 3.8 - Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "azureml_py38_tensorflow"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}