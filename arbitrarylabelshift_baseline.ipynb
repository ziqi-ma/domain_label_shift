{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from scipy import ndimage\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1635784167090
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code modified from  https://github.com/p-lambda/gradual_domain_adaptation\n",
        "\n",
        "# helper functions\n",
        "def get_preprocessed_cifar10():\n",
        "    (train_x, train_y), (test_x, test_y) = cifar10.load_data()\n",
        "    train_x, test_x = train_x / 255.0, test_x / 255.0\n",
        "    train_x, train_y = shuffle(train_x, train_y)\n",
        "    train_y = to_categorical(train_y)\n",
        "    test_y = to_categorical(test_y)\n",
        "    #train_x = np.expand_dims(np.array(train_x), axis=-1)\n",
        "    #test_x = np.expand_dims(np.array(test_x), axis=-1)\n",
        "    return (train_x, train_y), (test_x, test_y)\n",
        "\n",
        "def continually_rotate_images(xs, start_angle, end_angle):\n",
        "    new_xs = []\n",
        "    num_points = xs.shape[0]\n",
        "    for i in range(num_points):\n",
        "        angle = float(end_angle - start_angle) / num_points * i + start_angle\n",
        "        img = ndimage.rotate(xs[i], angle, reshape=False)\n",
        "        new_xs.append(img)\n",
        "    return np.array(new_xs)\n",
        "\n",
        "def sample_rotate_images(xs, start_angle, end_angle):\n",
        "    new_xs = []\n",
        "    num_points = xs.shape[0]\n",
        "    for i in range(num_points):\n",
        "        if start_angle == end_angle:\n",
        "            angle = start_angle\n",
        "        else:\n",
        "            angle = np.random.uniform(low=start_angle, high=end_angle)\n",
        "        img = ndimage.rotate(xs[i], angle, reshape=False)\n",
        "        new_xs.append(img)\n",
        "    return np.array(new_xs)\n",
        "\n",
        "def _transition_rotation_dataset(train_x, train_y, test_x, test_y,\n",
        "                                 source_angles, target_angles, inter_func,\n",
        "                                 src_train_end, src_val_end, inter_end, target_end):\n",
        "    assert(target_end <= train_x.shape[0])\n",
        "    assert(train_x.shape[0] == train_y.shape[0])\n",
        "    src_tr_x, src_tr_y = train_x[:src_train_end], train_y[:src_train_end]\n",
        "    src_tr_x = sample_rotate_images(src_tr_x, source_angles[0], source_angles[1])\n",
        "    src_val_x, src_val_y = train_x[src_train_end:src_val_end], train_y[src_train_end:src_val_end]\n",
        "    src_val_x = sample_rotate_images(src_val_x, source_angles[0], source_angles[1])\n",
        "    tmp_inter_x, inter_y = train_x[src_val_end:inter_end], train_y[src_val_end:inter_end]\n",
        "    inter_x = inter_func(tmp_inter_x)\n",
        "    dir_inter_x = sample_rotate_images(tmp_inter_x, target_angles[0], target_angles[1])\n",
        "    dir_inter_y = np.array(inter_y)\n",
        "    # dir is the \"intermediate\" samples directly shifted to the target angles (as comparison)\n",
        "    assert(inter_x.shape == dir_inter_x.shape)\n",
        "    trg_val_x, trg_val_y = train_x[inter_end:target_end], train_y[inter_end:target_end]\n",
        "    trg_val_x = sample_rotate_images(trg_val_x, target_angles[0], target_angles[1])\n",
        "    trg_test_x, trg_test_y = test_x, test_y\n",
        "    trg_test_x = sample_rotate_images(trg_test_x, target_angles[0], target_angles[1])\n",
        "    return (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x, inter_y,\n",
        "            dir_inter_x, dir_inter_y, trg_val_x, trg_val_y, trg_test_x, trg_test_y)\n",
        "    \n",
        "\n",
        "def make_rotated_dataset(train_x, train_y, test_x, test_y,\n",
        "                         source_angles, inter_angles, target_angles,\n",
        "                         src_train_end, src_val_end, inter_end, target_end):\n",
        "    inter_func = lambda x: continually_rotate_images(x, inter_angles[0], inter_angles[1])\n",
        "    return _transition_rotation_dataset(\n",
        "        train_x, train_y, test_x, test_y, source_angles, target_angles,\n",
        "        inter_func, src_train_end, src_val_end, inter_end, target_end)\n",
        "    \n",
        "def tweak_one_shift(x, y, rho):\n",
        "    # assign class \"3\" probability rho - i started with 0 but realized that doesn't composite well w rotation...\n",
        "    # since 0 rotated is still 0...\n",
        "    # evenly distribute among the other classes\n",
        "    # y is categorical, first reverse to numerical\n",
        "    y_num = np.argmax(y, axis=1)\n",
        "    x_res_list = []\n",
        "    y_res_list = []\n",
        "    n_total = x.shape[0]\n",
        "    n_classes = 10\n",
        "    n_others = int((1-rho)*n_total/(n_classes-1))\n",
        "    n_chosen = n_total - n_others*(n_classes-1)\n",
        "    # sample from zero class\n",
        "    zero_idxs = np.argwhere(y_num == 7)[:, 0]\n",
        "    zero_chosen = np.random.choice(zero_idxs, n_chosen)\n",
        "    x_res_list.append(x[zero_chosen])\n",
        "    y_res_list.append(y[zero_chosen])\n",
        "    for i in [0,1,2,3,4,5,6,8,9]:\n",
        "        cur_idxs = np.argwhere(y_num == i)[:,0]\n",
        "        cur_selected = np.random.choice(cur_idxs, n_others)\n",
        "        x_res_list.append(x[cur_selected])\n",
        "        y_res_list.append(y[cur_selected])\n",
        "    x_res = np.concatenate(x_res_list,axis=0)\n",
        "    y_res = np.concatenate(y_res_list,axis=0)\n",
        "    # shuffle\n",
        "    shuffled_idx = np.arange(x_res.shape[0])\n",
        "    np.random.shuffle(shuffled_idx)\n",
        "    x_res_shuffled = x_res[shuffled_idx]\n",
        "    y_res_shuffled = y_res[shuffled_idx]\n",
        "    return x_res_shuffled, y_res_shuffled\n",
        "\n",
        "def resample_class_dist(x, y, p_vec): # the p_vec could be e.g. drawn from Dirichlet dist.\n",
        "    n_total = x.shape[0]\n",
        "    y_ordinal = np.argmax(y,axis=1)\n",
        "    px_counts = p_vec * n_total\n",
        "    x_res_list = []\n",
        "    y_res_list = []\n",
        "    for i in range(10):\n",
        "        cur_idxs = np.argwhere(y_ordinal == i)[:,0]\n",
        "        #print(cur_idxs)\n",
        "        if len(cur_idxs) == 0:\n",
        "            continue\n",
        "        cur_selected = np.random.choice(cur_idxs, int(px_counts[i]))\n",
        "        x_res_list.append(x[cur_selected])\n",
        "        y_res_list.append(y[cur_selected])\n",
        "    x_res = np.concatenate(x_res_list,axis=0)\n",
        "    y_res = np.concatenate(y_res_list,axis=0)\n",
        "    # shuffle\n",
        "    shuffled_idx = np.arange(x_res.shape[0])\n",
        "    np.random.shuffle(shuffled_idx)\n",
        "    x_res_shuffled = x_res[shuffled_idx]\n",
        "    y_res_shuffled = y_res[shuffled_idx]\n",
        "    return x_res_shuffled, y_res_shuffled\n",
        "\n",
        "def rotated_cifar10_60_data_func_nols():\n",
        "    (train_x, train_y), (test_x, test_y) = get_preprocessed_cifar10()\n",
        "    return make_rotated_dataset(\n",
        "        train_x, train_y, test_x, test_y, [0.0, 2.0], [2.0, 20.0], [18.0, 20.0],\n",
        "        25000, 26000, 48000, 50000)\n",
        "\n",
        "'''\n",
        "def rotated_cifar10_60_data_func_tweakone(interval, target_rho, source_rho = 0.1):\n",
        "    # interval is the granularity of label shift (change rho of shift per interval)\n",
        "    (train_x, train_y), (test_x, test_y) = get_preprocessed_cifar10()\n",
        "    (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x, inter_y,\n",
        "     dir_inter_x, dir_inter_y, trg_val_x, trg_val_y, trg_test_x, trg_test_y) = make_rotated_dataset(\n",
        "        train_x, train_y, test_x, test_y, [0.0, 2.0], [2.0, 20.0], [18.0, 20.0],\n",
        "        25000, 26000, 48000, 50000)\n",
        "    # add label shift\n",
        "    # for intermediate images we also introduce intermediate shift with granularity of interval\n",
        "    n_batches = int(inter_x.shape[0]/interval)+1\n",
        "    rho_list = np.linspace(source_rho, target_rho, n_batches)\n",
        "    inter_x_labelshifted = []\n",
        "    inter_y_labelshifted = []\n",
        "    for i in range(n_batches):\n",
        "        if (i+1)*interval <= inter_x.shape[0]:\n",
        "            cur_x = inter_x[i*interval:(i+1)*interval]\n",
        "            cur_y = inter_y[i*interval:(i+1)*interval]\n",
        "        else:\n",
        "            cur_x = inter_x[i*interval:]\n",
        "            cur_y = inter_y[i*interval:]\n",
        "        cur_shifted_x, cur_shifted_y = tweak_one_shift(cur_x, cur_y, rho_list[i])\n",
        "        inter_x_labelshifted.append(cur_shifted_x)\n",
        "        inter_y_labelshifted.append(cur_shifted_y)\n",
        "    inter_x_ls = np.concatenate(inter_x_labelshifted, axis=0)\n",
        "    inter_y_ls = np.concatenate(inter_y_labelshifted, axis=0)\n",
        "    \n",
        "    # dir_inter_x and dir_inter_y are for comparison (directly self-train on target)\n",
        "    dir_inter_x_ls, dir_inter_y_ls = tweak_one_shift(dir_inter_x, dir_inter_y, target_rho)\n",
        "\n",
        "    # shift all of trg_val_x, trg_val_y, trg_test_x, trg_test_y\n",
        "    trg_val_x_ls, trg_val_y_ls = tweak_one_shift(trg_val_x, trg_val_y, target_rho)\n",
        "    trg_test_x_ls, trg_test_y_ls = tweak_one_shift(trg_test_x, trg_test_y, target_rho)\n",
        "\n",
        "    return (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x_ls, inter_y_ls,\n",
        "            dir_inter_x_ls, dir_inter_y_ls, trg_val_x_ls, trg_val_y_ls, trg_test_x_ls, trg_test_y_ls)\n",
        "'''    \n",
        "\n",
        "def rotated_cifar10_60_data_func_dirichlet(interval, alpha, n_classes=10):\n",
        "    # interval is the granularity of x|y shift\n",
        "    # x|y shift is gradual, but each step we have arbitrary label shift\n",
        "    # return array of all dist vecs to get oracle training\n",
        "    (train_x, train_y), (test_x, test_y) = get_preprocessed_cifar10()\n",
        "    (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x, inter_y,\n",
        "     dir_inter_x, dir_inter_y, trg_val_x, trg_val_y, trg_test_x, trg_test_y) = make_rotated_dataset(\n",
        "        train_x, train_y, test_x, test_y, [0.0, 2.0], [2.0, 20.0], [18.0, 20.0],\n",
        "        25000, 26000, 48000, 50000)\n",
        "    # add label shift\n",
        "    # for intermediate images, each step introduce arbitrary shift\n",
        "    n_batches = int(inter_x.shape[0]/interval)\n",
        "    inter_x_labelshifted = []\n",
        "    inter_y_labelshifted = []\n",
        "    dist_store = np.zeros((n_batches+1, n_classes))\n",
        "    for i in range(n_batches):\n",
        "        if i == 0:\n",
        "            cur_prob = np.ones(n_classes)/n_classes # start with uniform, no need to correct on first step\n",
        "        else:\n",
        "            cur_prob = np.random.dirichlet(np.array([alpha]*n_classes))\n",
        "        dist_store[i,:] = cur_prob\n",
        "        if (i+1)*interval <= inter_x.shape[0]:\n",
        "            cur_x = inter_x[i*interval:(i+1)*interval]\n",
        "            cur_y = inter_y[i*interval:(i+1)*interval]\n",
        "        else:\n",
        "            cur_x = inter_x[i*interval:]\n",
        "            cur_y = inter_y[i*interval:]\n",
        "        cur_shifted_x, cur_shifted_y = resample_class_dist(cur_x, cur_y, cur_prob)\n",
        "        inter_x_labelshifted.append(cur_shifted_x)\n",
        "        inter_y_labelshifted.append(cur_shifted_y)\n",
        "    inter_x_ls = np.concatenate(inter_x_labelshifted, axis=0)\n",
        "    inter_y_ls = np.concatenate(inter_y_labelshifted, axis=0)\n",
        "    \n",
        "    final_px = np.random.dirichlet(np.array([alpha]*n_classes))\n",
        "    dist_store[n_batches,:] = final_px\n",
        "    # dir_inter_x and dir_inter_y are for comparison (directly self-train on target)\n",
        "    dir_inter_x_ls, dir_inter_y_ls = resample_class_dist(dir_inter_x, dir_inter_y, final_px)\n",
        "    \n",
        "    # shift all of trg_val_x, trg_val_y, trg_test_x, trg_test_y\n",
        "    trg_val_x_ls, trg_val_y_ls = resample_class_dist(trg_val_x, trg_val_y, final_px)\n",
        "    trg_test_x_ls, trg_test_y_ls = resample_class_dist(trg_test_x, trg_test_y, final_px)\n",
        "    return (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x_ls, inter_y_ls,\n",
        "            dir_inter_x_ls, dir_inter_y_ls, trg_val_x_ls, trg_val_y_ls, trg_test_x_ls, trg_test_y_ls, dist_store)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635784170460
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training functions\n",
        "def self_train_once(student, teacher, unsup_x, confidence_q=0.1, epochs=100, class_ws=None):\n",
        "    # Do one bootstrapping step on unsup_x, where pred_model is used to make predictions,\n",
        "    # and we use these predictions to update model.\n",
        "    logits = teacher.predict(np.concatenate([unsup_x]))\n",
        "    confidence = np.amax(logits, axis=1) - np.amin(logits, axis=1)\n",
        "    alpha = np.quantile(confidence, confidence_q)\n",
        "    indices = np.argwhere(confidence >= alpha)[:, 0]\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    preds = to_categorical(preds, num_classes=10)\n",
        "    # apply class weights\n",
        "    if class_ws is not None:\n",
        "        # get class ws dict\n",
        "        cw = {}\n",
        "        for i in range(10):\n",
        "            cw[i] = class_ws[i]\n",
        "        student.fit(unsup_x[indices], preds[indices], epochs=epochs, class_weight = cw, verbose=False)\n",
        "    else:\n",
        "        student.fit(unsup_x[indices], preds[indices], epochs=epochs, verbose=False)\n",
        "\n",
        "def soft_self_train_once(student, teacher, unsup_x, epochs=100):\n",
        "    probs = teacher.predict(np.concatenate([unsup_x]))\n",
        "    student.fit(unsup_x, probs, epochs=epochs, verbose=False)\n",
        "\n",
        "def self_train(teacher, unsup_x, confidence_q=0.1, epochs=100, repeats=1,\n",
        "               target_x=None, target_y=None, soft=False):\n",
        "    accuracies = []\n",
        "    student = teacher\n",
        "    for i in range(repeats):\n",
        "        if soft:\n",
        "            soft_self_train_once(student, teacher, unsup_x, epochs)\n",
        "        else:\n",
        "            self_train_once(student, teacher, unsup_x, confidence_q, epochs)\n",
        "        if target_x is not None and target_y is not None:\n",
        "            _, accuracy = student.evaluate(target_x, target_y, verbose=True)\n",
        "            accuracies.append(accuracy)\n",
        "        teacher = student\n",
        "    return accuracies, student\n",
        "\n",
        "def gradual_self_train(teacher, unsup_x, debug_y, interval, confidence_q=0.1,\n",
        "                       epochs=100, soft=False):\n",
        "    upper_idx = int(unsup_x.shape[0] / interval)\n",
        "    accuracies = []\n",
        "    student = teacher\n",
        "    for i in range(upper_idx):\n",
        "        cur_xs = unsup_x[interval*i:interval*(i+1)]\n",
        "        cur_ys = debug_y[interval*i:interval*(i+1)]\n",
        "        # _, student = self_train(\n",
        "        #     student_func, teacher, unsup_x, confidence_q, epochs, repeats=2)\n",
        "        if soft:\n",
        "            soft_self_train_once(student, teacher, cur_xs, epochs)\n",
        "        else:\n",
        "            self_train_once(student, teacher, cur_xs, confidence_q, epochs)\n",
        "        _, accuracy = student.evaluate(cur_xs, cur_ys)\n",
        "        accuracies.append(accuracy)\n",
        "        teacher = student\n",
        "    return accuracies, student\n",
        "\n",
        "def gradual_corrected_self_train(teacher, unsup_x, debug_y, interval, dist_store, confidence_q=0.1,\n",
        "                       epochs=100, soft=False):\n",
        "    upper_idx = int(unsup_x.shape[0] / interval)\n",
        "    accuracies = []\n",
        "    student = teacher\n",
        "    for i in range(upper_idx):\n",
        "        cur_xs = unsup_x[interval*i:interval*(i+1)]\n",
        "        cur_ys = debug_y[interval*i:interval*(i+1)]\n",
        "       \n",
        "        # weight by distance store\n",
        "        class_ws = dist_store[i+1,:]/dist_store[i,:]\n",
        "        # normalize\n",
        "        class_ws = class_ws / np.mean(class_ws)\n",
        "        \n",
        "        if soft:\n",
        "            soft_self_train_once(student, teacher, cur_xs, epochs)\n",
        "        else:\n",
        "            self_train_once(student, teacher, cur_xs, confidence_q, epochs, class_ws=class_ws)\n",
        "        _, accuracy = student.evaluate(cur_xs, cur_ys)\n",
        "        accuracies.append(accuracy)\n",
        "        teacher = student\n",
        "    return accuracies, student"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635784171268
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "def simple_softmax_conv_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(10, activation='softmax')) \n",
        "    # compile model\n",
        "    \n",
        "    model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635784172160
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rand_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "def shuffle(xs, ys):\n",
        "    indices = list(range(len(xs)))\n",
        "    np.random.shuffle(indices)\n",
        "    return xs[indices], ys[indices]"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635784173150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exp(seed, label_shift, tweak_one_rho = None, dirichlet_alpha = None, interval=2000, epochs=30, conf_q=0.1, n_classes=10):\n",
        "    # get data\n",
        "    if label_shift == \"NO_LS\":\n",
        "        (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x, inter_y, dir_inter_x, dir_inter_y,\n",
        "         trg_eval_x, trg_eval_y, trg_test_x, trg_test_y) = rotated_cifar10_60_data_func_nols()\n",
        "        n_batches = int(inter_x.shape[0]/interval)\n",
        "        dist_store = np.ones((n_batches+1, n_classes))\n",
        "    elif label_shift == \"TWEAK_ONE\":\n",
        "        if tweak_one_rho is None:\n",
        "            print(\"no tweak one rho!\")\n",
        "            return\n",
        "        (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x, inter_y, dir_inter_x, dir_inter_y,\n",
        "         trg_eval_x, trg_eval_y, trg_test_x, trg_test_y) = rotated_cifar10_60_data_func_tweakone(interval, tweak_one_rho)\n",
        "    elif label_shift == \"DIRICHLET\":\n",
        "        if dirichlet_alpha is None:\n",
        "            print(\"no dirichlet alpha!\")\n",
        "            return\n",
        "        (src_tr_x, src_tr_y, src_val_x, src_val_y, inter_x, inter_y, dir_inter_x, dir_inter_y,\n",
        "         trg_eval_x, trg_eval_y, trg_test_x, trg_test_y, diststore) = rotated_cifar10_60_data_func_dirichlet(interval, dirichlet_alpha)\n",
        "        \n",
        "        print(diststore)\n",
        "    # set seed\n",
        "    rand_seed(seed)\n",
        "    \n",
        "    # Train source model\n",
        "    source_model = simple_softmax_conv_model()\n",
        "    source_model.fit(src_tr_x, src_tr_y, epochs=epochs, verbose=False)\n",
        "    _, src_acc = source_model.evaluate(src_val_x, src_val_y)\n",
        "    _, srcmodel_acc = source_model.evaluate(trg_eval_x, trg_eval_y)\n",
        "\n",
        "    # corrected gradual self training (assuming we know label shift)\n",
        "    if label_shift != \"NO_LS\":\n",
        "        print(\"\\n\\n Gradual corrected self-training:\")\n",
        "        teacher = simple_softmax_conv_model()\n",
        "        teacher.set_weights(source_model.get_weights())\n",
        "        gradual_corrected_accuracies, student = gradual_corrected_self_train(teacher, inter_x, inter_y, interval, diststore, epochs=epochs,\n",
        "            confidence_q=conf_q)\n",
        "        _, acc = student.evaluate(trg_eval_x, trg_eval_y)\n",
        "        gradual_corrected_accuracies.append(acc)\n",
        "    \n",
        "    # Train directly on target (oracle)\n",
        "    print(\"\\n\\n Direct train on target:\")\n",
        "    target_model = simple_softmax_conv_model()\n",
        "    target_model.fit(dir_inter_x, dir_inter_y, epochs=epochs, verbose=False)\n",
        "    _, oracle_target_acc = target_model.evaluate(trg_eval_x, trg_eval_y)\n",
        "    \n",
        "    # comment this out bc we already know it's bad\n",
        "    \n",
        "    # self training on target (bad baseline)\n",
        "    #NUM_REPEATS = 1 # they repeat more in the paper, but small difference\n",
        "    #print(\"\\n\\n Direct self train on target:\")\n",
        "    #teacher = simple_softmax_conv_model()\n",
        "    #teacher.set_weights(source_model.get_weights())\n",
        "    #target_accuracies, _ = self_train(teacher, dir_inter_x, epochs=epochs, target_x=trg_eval_x,\n",
        "            #target_y=trg_eval_y, repeats=NUM_REPEATS, confidence_q=conf_q)\n",
        "    \n",
        "    # Gradual self-training (paper baseline)\n",
        "    print(\"\\n\\n Gradual self-training:\")\n",
        "    teacher = simple_softmax_conv_model()\n",
        "    teacher.set_weights(source_model.get_weights())\n",
        "    gradual_accuracies, student = gradual_self_train(teacher, inter_x, inter_y, interval, epochs=epochs,\n",
        "            confidence_q=conf_q)\n",
        "    _, acc = student.evaluate(trg_eval_x, trg_eval_y)\n",
        "    gradual_accuracies.append(acc)\n",
        "    \n",
        "    \n",
        "    print(f\"Source model acc on target: {srcmodel_acc}\")\n",
        "    #print(f\"direct self train on target: {target_accuracies[-1]}\")\n",
        "    print(f\"gradual self training accuracies: {gradual_accuracies[-1]}\")\n",
        "    print(f\"gradual labelshift corrected self training accuracies: {gradual_corrected_accuracies[-1]}\")\n",
        "    print(f\"oracle accuracy: {oracle_target_acc}\")\n",
        "    \n",
        "    \n",
        "    return np.array([srcmodel_acc, gradual_accuracies[-1], gradual_corrected_accuracies[-1], oracle_target_acc]), diststore"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635823479669
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exp_dirichlet(seed):\n",
        "    alpha = 9\n",
        "    res, diststore = exp(seed, \"DIRICHLET\", dirichlet_alpha=alpha)\n",
        "    return res, diststore\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635911745471
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_nols, diststore_nols = exp(1, \"NO_LS\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "32/32 [==============================] - 1s 19ms/step - loss: 0.5403 - accuracy: 0.8160\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 1.0834 - accuracy: 0.6565\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Direct train on target:\n63/63 [==============================] - 1s 19ms/step - loss: 0.6280 - accuracy: 0.7895\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual self-training:\n63/63 [==============================] - 1s 19ms/step - loss: 1.4671 - accuracy: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 1.8732 - accuracy: 0.7735\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 20ms/step - loss: 2.1594 - accuracy: 0.7465\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 24ms/step - loss: 2.1640 - accuracy: 0.7295\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 24ms/step - loss: 2.7694 - accuracy: 0.6755\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 24ms/step - loss: 3.2317 - accuracy: 0.6290\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 3.5151 - accuracy: 0.5875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 20ms/step - loss: 3.5848 - accuracy: 0.6170\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 20ms/step - loss: 3.9859 - accuracy: 0.5730\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 4.6440 - accuracy: 0.5315\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 4.7907 - accuracy: 0.4995\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 19ms/step - loss: 4.0248 - accuracy: 0.4895\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nSource model acc on target: 0.656499981880188\ngradual self training accuracies: 0.4894999861717224\n"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'gradual_corrected_accuracies' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-ded642d25638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres_nols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiststore_nols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NO_LS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-de4f08721794>\u001b[0m in \u001b[0;36mexp\u001b[0;34m(seed, label_shift, tweak_one_rho, dirichlet_alpha, interval, epochs, conf_q, n_classes)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m#print(f\"direct self train on target: {target_accuracies[-1]}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"gradual self training accuracies: {gradual_accuracies[-1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"gradual labelshift corrected self training accuracies: {gradual_corrected_accuracies[-1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"oracle accuracy: {oracle_target_acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrcmodel_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradual_accuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradual_corrected_accuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moracle_target_acc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiststore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'gradual_corrected_accuracies' referenced before assignment"
          ]
        }
      ],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = np.zeros((10,4))\n",
        "diststore = np.zeros((10,120))\n",
        "for seed in range(10):\n",
        "    res[seed,:], cur_diststore = exp_dirichlet(seed)\n",
        "    diststore[seed,:] = cur_diststore.reshape(120)\n",
        "    np.savetxt(\"res1.txt\", res)\n",
        "    np.savetxt(\"distr1.txt\", diststore)\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[0.1        0.1        0.1        0.1        0.1        0.1\n  0.1        0.1        0.1        0.1       ]\n [0.10081323 0.08616254 0.10663195 0.13304498 0.08751404 0.07846928\n  0.08029117 0.06230777 0.16890197 0.09586307]\n [0.07594351 0.10361178 0.12200732 0.13738215 0.07988988 0.12916356\n  0.11213071 0.06582846 0.09146465 0.08257799]\n [0.09083009 0.08702777 0.08633376 0.09255725 0.10189581 0.14481787\n  0.08622025 0.05551107 0.14065605 0.11415008]\n [0.08504783 0.16203572 0.08258321 0.07924426 0.11545605 0.14150627\n  0.05026622 0.06709323 0.09579366 0.12097356]\n [0.14346732 0.05881296 0.07453145 0.09448652 0.0756651  0.16569163\n  0.09039187 0.0951535  0.06591184 0.13588779]\n [0.1048512  0.08798365 0.14801199 0.10782537 0.06983402 0.10299994\n  0.09306201 0.07264878 0.10558665 0.10719638]\n [0.08143226 0.11377506 0.1422721  0.05886171 0.13845412 0.07866414\n  0.09098645 0.10150437 0.10904844 0.08500135]\n [0.07829499 0.10796098 0.06821976 0.08646457 0.12580558 0.12744053\n  0.11911877 0.05915042 0.1617303  0.06581411]\n [0.09125256 0.15295113 0.08829953 0.12299274 0.04884773 0.05512947\n  0.07446488 0.10028965 0.14491905 0.12085327]\n [0.11241191 0.10094525 0.11303333 0.08212658 0.09947495 0.15040427\n  0.06652925 0.07379317 0.09861558 0.10266571]\n [0.04599162 0.07199181 0.08498579 0.16093213 0.06813103 0.12715187\n  0.10918042 0.12376682 0.09846215 0.10940635]]\n32/32 [==============================] - 1s 21ms/step - loss: 0.4922 - accuracy: 0.8370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 1.3097 - accuracy: 0.5926\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual corrected self-training:\n63/63 [==============================] - 1s 21ms/step - loss: 1.4863 - accuracy: 0.8295\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.3080 - accuracy: 0.7395\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.0708 - accuracy: 0.6885\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.0077 - accuracy: 0.7075\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.6121 - accuracy: 0.7305\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.5375 - accuracy: 0.6655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.8367 - accuracy: 0.6200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 27ms/step - loss: 4.0595 - accuracy: 0.6075\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 4.0071 - accuracy: 0.5860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 4.7234 - accuracy: 0.5445\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 3.8016 - accuracy: 0.4947\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Direct train on target:\n63/63 [==============================] - 2s 23ms/step - loss: 0.7731 - accuracy: 0.7642\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual self-training:\n63/63 [==============================] - 2s 23ms/step - loss: 1.4243 - accuracy: 0.8320\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 2.6427 - accuracy: 0.7330\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 2.7121 - accuracy: 0.6990\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 3.2065 - accuracy: 0.6900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 3.1750 - accuracy: 0.6880\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 3.9917 - accuracy: 0.6105\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 4.6264 - accuracy: 0.5845\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.6606 - accuracy: 0.5625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 5.0226 - accuracy: 0.5480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 6.2881 - accuracy: 0.4515\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 6.0612 - accuracy: 0.3778\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nSource model acc on target: 0.5925740003585815\ngradual self training accuracies: 0.3778223693370819\ngradual labelshift corrected self training accuracies: 0.4947315752506256\noracle accuracy: 0.7641746401786804\n[[0.1        0.1        0.1        0.1        0.1        0.1\n  0.1        0.1        0.1        0.1       ]\n [0.11469894 0.09090941 0.05441229 0.12718412 0.07247133 0.07968921\n  0.14933051 0.07622477 0.08758218 0.14749724]\n [0.11295945 0.1190082  0.10818827 0.11604016 0.1003163  0.10164441\n  0.06623258 0.07681715 0.1328344  0.06595907]\n [0.12151292 0.13635586 0.15799553 0.05440401 0.09125145 0.09798531\n  0.11178924 0.10159584 0.0762024  0.05090745]\n [0.10762764 0.08706216 0.0734304  0.07493021 0.09816503 0.08337693\n  0.12086877 0.13432701 0.13994649 0.08026535]\n [0.09392596 0.09631988 0.09457774 0.1162185  0.13661842 0.05338355\n  0.06833289 0.17036977 0.10451268 0.0657406 ]\n [0.1206559  0.06947543 0.06793281 0.10331883 0.08235109 0.11196965\n  0.08265858 0.14333653 0.15241974 0.06588144]\n [0.07267961 0.09216456 0.1002711  0.08972794 0.06612285 0.11038017\n  0.11329935 0.13948753 0.11713434 0.09873254]\n [0.08908279 0.08619175 0.09698195 0.12428897 0.09311083 0.0573727\n  0.13116236 0.04999572 0.16023677 0.11157615]\n [0.12163452 0.09959418 0.12991996 0.13853931 0.07592044 0.07278564\n  0.09081353 0.07339803 0.0514698  0.1459246 ]\n [0.06131131 0.13042873 0.0829039  0.08801897 0.10551961 0.10280296\n  0.10422782 0.08014361 0.10864941 0.13599368]\n [0.12920473 0.08443602 0.13961982 0.08001512 0.10756646 0.12929508\n  0.07415154 0.10439946 0.05665471 0.09465705]]\n32/32 [==============================] - 1s 21ms/step - loss: 0.5146 - accuracy: 0.8230\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 1.0298 - accuracy: 0.6633\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual corrected self-training:\n63/63 [==============================] - 2s 28ms/step - loss: 1.5205 - accuracy: 0.8245\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 29ms/step - loss: 2.1996 - accuracy: 0.7810\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 27ms/step - loss: 3.1283 - accuracy: 0.7015\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 20ms/step - loss: 3.2703 - accuracy: 0.6860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.2384 - accuracy: 0.6805\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.0417 - accuracy: 0.5850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.0508 - accuracy: 0.5925\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.7426 - accuracy: 0.5635\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.6984 - accuracy: 0.5385\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 6.8851 - accuracy: 0.4390\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.9555 - accuracy: 0.4704\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Direct train on target:\n63/63 [==============================] - 2s 26ms/step - loss: 0.7503 - accuracy: 0.7771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual self-training:\n63/63 [==============================] - 2s 27ms/step - loss: 1.4973 - accuracy: 0.8300\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.1771 - accuracy: 0.7730\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.0647 - accuracy: 0.6980\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.1942 - accuracy: 0.6785\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.8245 - accuracy: 0.7065\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.5347 - accuracy: 0.6040\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.5164 - accuracy: 0.6080\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.2624 - accuracy: 0.6265\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.4582 - accuracy: 0.6010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.9149 - accuracy: 0.5410\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.2684 - accuracy: 0.5085\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nSource model acc on target: 0.6633266806602478\ngradual self training accuracies: 0.5085170269012451\ngradual labelshift corrected self training accuracies: 0.47044089436531067\noracle accuracy: 0.7770541310310364\n[[0.1        0.1        0.1        0.1        0.1        0.1\n  0.1        0.1        0.1        0.1       ]\n [0.08588166 0.06618623 0.08486893 0.08184247 0.11969912 0.11333358\n  0.09673609 0.14341056 0.11596175 0.0920796 ]\n [0.10284069 0.09789282 0.07444785 0.04831671 0.19967337 0.06411537\n  0.07123278 0.14831261 0.11365244 0.07951537]\n [0.08988903 0.08990013 0.09777063 0.09969324 0.10622472 0.09297078\n  0.03294534 0.11731802 0.21174657 0.06154155]\n [0.06926217 0.08840001 0.07251985 0.06897811 0.13331346 0.07166517\n  0.13504272 0.09218265 0.10373205 0.16490381]\n [0.07460396 0.09112093 0.09686582 0.0922614  0.08761875 0.06952171\n  0.08101087 0.13269414 0.12325814 0.15104427]\n [0.12449675 0.05123971 0.09273407 0.14706659 0.10553192 0.07651265\n  0.0643625  0.13530744 0.09911534 0.10363303]\n [0.11196352 0.10500026 0.10793975 0.09320546 0.1065722  0.07760084\n  0.14141368 0.11182877 0.0463024  0.09817312]\n [0.11971421 0.13489192 0.1091232  0.07526901 0.06196596 0.10108324\n  0.07512771 0.14973223 0.08348897 0.08960355]\n [0.06917742 0.05567575 0.049735   0.14599358 0.14842925 0.14501988\n  0.06079842 0.11738057 0.07289044 0.13489969]\n [0.15845328 0.12372006 0.10740048 0.08745863 0.08699969 0.0830761\n  0.10805993 0.10889976 0.08199164 0.05394044]\n [0.06871787 0.1068684  0.14869382 0.05320203 0.12208225 0.12614436\n  0.06429772 0.06412806 0.13581876 0.11004675]]\n32/32 [==============================] - 1s 22ms/step - loss: 0.5310 - accuracy: 0.8210\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 1.1686 - accuracy: 0.6318\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual corrected self-training:\n63/63 [==============================] - 2s 22ms/step - loss: 1.8772 - accuracy: 0.7945\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 2.5468 - accuracy: 0.7480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.6485 - accuracy: 0.7345\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.4840 - accuracy: 0.6640\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.8941 - accuracy: 0.6885\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.7388 - accuracy: 0.6355\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.1333 - accuracy: 0.5440\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.1046 - accuracy: 0.5835\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.3099 - accuracy: 0.5290\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 6.4194 - accuracy: 0.4735\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.2837 - accuracy: 0.4314\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Direct train on target:\n63/63 [==============================] - 2s 21ms/step - loss: 0.6940 - accuracy: 0.7906\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual self-training:\n63/63 [==============================] - 2s 22ms/step - loss: 1.9673 - accuracy: 0.8010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.2237 - accuracy: 0.7775\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 2.5516 - accuracy: 0.7295\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.9582 - accuracy: 0.6405\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.1579 - accuracy: 0.6710\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.1605 - accuracy: 0.5995\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.7633 - accuracy: 0.4825\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.1905 - accuracy: 0.5145\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 6.5334 - accuracy: 0.4395\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 7.4065 - accuracy: 0.3795\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 6.6115 - accuracy: 0.3262\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nSource model acc on target: 0.6317635178565979\ngradual self training accuracies: 0.3261522948741913\ngradual labelshift corrected self training accuracies: 0.43136271834373474\noracle accuracy: 0.7905811667442322\n[[0.1        0.1        0.1        0.1        0.1        0.1\n  0.1        0.1        0.1        0.1       ]\n [0.06923558 0.12747173 0.08058471 0.10248222 0.08587239 0.14039775\n  0.11841693 0.12409282 0.05573068 0.09571519]\n [0.15417507 0.06412214 0.13938624 0.13749514 0.10818597 0.08936725\n  0.07055817 0.07267371 0.08013077 0.08390554]\n [0.16962659 0.03881025 0.06503914 0.11261743 0.11409648 0.05400095\n  0.10096709 0.11183632 0.15330115 0.07970459]\n [0.06867077 0.0808081  0.09695809 0.163744   0.09119833 0.06850363\n  0.08330995 0.12386572 0.03722486 0.18571655]\n [0.09873867 0.12475934 0.2239902  0.12291122 0.09718401 0.06105714\n  0.07039058 0.05492546 0.08945215 0.05659122]\n [0.08392986 0.07852502 0.12270136 0.12737474 0.07352912 0.12202617\n  0.15011509 0.05314526 0.14917101 0.03948238]\n [0.19051138 0.07376785 0.0959188  0.03950778 0.09021807 0.1275203\n  0.07666634 0.10771928 0.12165194 0.07651826]\n [0.12478115 0.09614462 0.08566194 0.17166872 0.06984059 0.05834788\n  0.04000388 0.13457352 0.08920732 0.12977037]\n [0.18119311 0.07521496 0.05811521 0.0495797  0.13183023 0.08449031\n  0.15588603 0.13790873 0.05817725 0.06760447]\n [0.06461731 0.07772004 0.11526373 0.10125754 0.13366243 0.05652062\n  0.0703016  0.11276857 0.14322996 0.1246582 ]\n [0.09271187 0.17105687 0.05445352 0.06581647 0.11124298 0.1092747\n  0.13694556 0.09078966 0.09134287 0.07636549]]\n32/32 [==============================] - 1s 21ms/step - loss: 0.6006 - accuracy: 0.8150\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 0.9271 - accuracy: 0.6991\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual corrected self-training:\n63/63 [==============================] - 1s 21ms/step - loss: 2.0333 - accuracy: 0.7815\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.5061 - accuracy: 0.7365\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.8413 - accuracy: 0.6240\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.1868 - accuracy: 0.6735\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.9568 - accuracy: 0.6235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.0687 - accuracy: 0.5575\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.6015 - accuracy: 0.5870\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.7530 - accuracy: 0.5695\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 6.3047 - accuracy: 0.4705\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.9035 - accuracy: 0.5575\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.5914 - accuracy: 0.5496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Direct train on target:\n63/63 [==============================] - 1s 21ms/step - loss: 0.5411 - accuracy: 0.8260\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual self-training:\n63/63 [==============================] - 2s 21ms/step - loss: 1.9927 - accuracy: 0.7830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.5062 - accuracy: 0.7270\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.8581 - accuracy: 0.6525\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.1357 - accuracy: 0.6970\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.5244 - accuracy: 0.6695\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.2413 - accuracy: 0.6155\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.1738 - accuracy: 0.6150\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.6638 - accuracy: 0.5870\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 5.3918 - accuracy: 0.5295\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.5341 - accuracy: 0.5785\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.9840 - accuracy: 0.5767\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nSource model acc on target: 0.6990972757339478\ngradual self training accuracies: 0.5767301917076111\ngradual labelshift corrected self training accuracies: 0.5496489405632019\noracle accuracy: 0.8259779214859009\n[[0.1        0.1        0.1        0.1        0.1        0.1\n  0.1        0.1        0.1        0.1       ]\n [0.11509914 0.02942586 0.24582327 0.08437082 0.05390888 0.15232443\n  0.07573077 0.08257248 0.11372849 0.04701587]\n [0.09149116 0.10379008 0.16179588 0.0646131  0.07827723 0.09500148\n  0.07716207 0.12276542 0.06586488 0.13923869]\n [0.09936873 0.1321561  0.11833529 0.0941369  0.07778212 0.06714028\n  0.11593323 0.0824756  0.09066899 0.12200276]\n [0.113597   0.11359571 0.08555171 0.10145688 0.08837095 0.09338951\n  0.10982357 0.05330268 0.14207056 0.09884143]\n [0.06803033 0.07916089 0.08381837 0.13201401 0.12369347 0.08118973\n  0.14525806 0.11590847 0.10001422 0.07091245]\n [0.10420714 0.11974    0.08553623 0.09213559 0.12822264 0.13622446\n  0.10556572 0.09745463 0.05877429 0.07213929]\n [0.12926312 0.07082973 0.1237319  0.07539469 0.1086848  0.10500302\n  0.15328653 0.06887817 0.08898336 0.07594469]\n [0.0723861  0.07184712 0.07638166 0.12030265 0.08655841 0.13281744\n  0.0961339  0.10070905 0.11462213 0.12824154]\n [0.08776212 0.10891342 0.19566752 0.0620973  0.10947    0.07599397\n  0.07843489 0.12070938 0.05785999 0.10309142]\n [0.04222463 0.12072841 0.09699441 0.16456738 0.09623448 0.10749677\n  0.11969518 0.08990268 0.07611454 0.08604152]\n [0.07749219 0.07417845 0.07931663 0.09231096 0.06745664 0.15339869\n  0.1165871  0.19477373 0.06601867 0.07846694]]\n32/32 [==============================] - 1s 20ms/step - loss: 0.6211 - accuracy: 0.8020\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 1.1230 - accuracy: 0.6479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual corrected self-training:\n63/63 [==============================] - 2s 21ms/step - loss: 1.7115 - accuracy: 0.8045\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.8840 - accuracy: 0.7110\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.2180 - accuracy: 0.6915\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.9122 - accuracy: 0.7090\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.7091 - accuracy: 0.6465\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.7146 - accuracy: 0.6225\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.1809 - accuracy: 0.5335\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 26ms/step - loss: 4.9761 - accuracy: 0.5135\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.3047 - accuracy: 0.5070\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 6.5095 - accuracy: 0.4485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.1573 - accuracy: 0.4458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Direct train on target:\n63/63 [==============================] - 1s 21ms/step - loss: 0.8245 - accuracy: 0.7638\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual self-training:\n63/63 [==============================] - 2s 21ms/step - loss: 1.7536 - accuracy: 0.8060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.6677 - accuracy: 0.7220\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.8224 - accuracy: 0.7220\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.5681 - accuracy: 0.7445\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.0164 - accuracy: 0.7145\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 3.6171 - accuracy: 0.6730\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 27ms/step - loss: 4.1779 - accuracy: 0.6000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.1528 - accuracy: 0.5940\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.0891 - accuracy: 0.5830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.7323 - accuracy: 0.4895\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.0617 - accuracy: 0.4855\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nSource model acc on target: 0.6479438543319702\ngradual self training accuracies: 0.4854563772678375\ngradual labelshift corrected self training accuracies: 0.44583749771118164\noracle accuracy: 0.7637913823127747\n[[0.1        0.1        0.1        0.1        0.1        0.1\n  0.1        0.1        0.1        0.1       ]\n [0.11120731 0.10229337 0.13449728 0.07219156 0.0740642  0.10163356\n  0.10353872 0.12103584 0.13812786 0.04141031]\n [0.06044926 0.11182812 0.11786808 0.07250319 0.07707859 0.11690913\n  0.1227286  0.0972052  0.13685561 0.08657422]\n [0.14722711 0.07374522 0.061116   0.08582675 0.11654964 0.09044916\n  0.15715925 0.11915311 0.06596087 0.0828129 ]\n [0.04098793 0.10977332 0.08708481 0.12064328 0.08830977 0.06458561\n  0.08578624 0.10517314 0.12722633 0.17042955]\n [0.10281797 0.13881325 0.03541552 0.08658183 0.15902645 0.11521733\n  0.08190907 0.09050689 0.09788468 0.091827  ]\n [0.10213678 0.11244042 0.08686418 0.08336608 0.08011905 0.13623337\n  0.07896562 0.11957927 0.07008023 0.130215  ]\n [0.08434228 0.07614206 0.05654943 0.13083091 0.07597086 0.15908076\n  0.12237264 0.07962532 0.14321392 0.07187183]\n [0.07654673 0.15573144 0.11173358 0.08787303 0.09858204 0.0894452\n  0.10712447 0.0696628  0.06157286 0.14172785]\n [0.1077013  0.13157553 0.05101583 0.10605944 0.11590634 0.14824109\n  0.06981919 0.09017802 0.05215654 0.12734671]\n [0.10575584 0.13237335 0.08274886 0.11746206 0.10371351 0.09840241\n  0.06752556 0.10712691 0.07979448 0.10509702]\n [0.09969042 0.04206    0.04430779 0.1638526  0.12682979 0.09980329\n  0.12861026 0.10812547 0.1005209  0.0861995 ]]\n32/32 [==============================] - 1s 21ms/step - loss: 0.5546 - accuracy: 0.8090\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 1.1964 - accuracy: 0.6232\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual corrected self-training:\n63/63 [==============================] - 2s 21ms/step - loss: 1.6886 - accuracy: 0.8060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 2.6410 - accuracy: 0.7330\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 2.6248 - accuracy: 0.7300\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 2.4363 - accuracy: 0.7365\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.0631 - accuracy: 0.6920\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.5220 - accuracy: 0.6640\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.1837 - accuracy: 0.6090\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.4478 - accuracy: 0.5645\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.5131 - accuracy: 0.5700\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 5.5964 - accuracy: 0.5170\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 5.0231 - accuracy: 0.4855\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Direct train on target:\n63/63 [==============================] - 2s 28ms/step - loss: 0.7950 - accuracy: 0.7776\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual self-training:\n63/63 [==============================] - 2s 28ms/step - loss: 1.6992 - accuracy: 0.8010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 2.8924 - accuracy: 0.7230\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 2.7705 - accuracy: 0.7265\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.7237 - accuracy: 0.7180\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.3332 - accuracy: 0.6805\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.3227 - accuracy: 0.6730\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.7252 - accuracy: 0.6450\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.1063 - accuracy: 0.6240\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.5920 - accuracy: 0.6500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.2879 - accuracy: 0.5940\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.4236 - accuracy: 0.5616\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nSource model acc on target: 0.6232464909553528\ngradual self training accuracies: 0.5616232752799988\ngradual labelshift corrected self training accuracies: 0.4854709506034851\noracle accuracy: 0.7775551080703735\n[[0.1        0.1        0.1        0.1        0.1        0.1\n  0.1        0.1        0.1        0.1       ]\n [0.10075104 0.06744934 0.05582278 0.14487373 0.09959917 0.10957668\n  0.14222664 0.03563275 0.12835286 0.11571503]\n [0.04429889 0.16980419 0.09272435 0.12967798 0.09094371 0.13989383\n  0.05796678 0.13081627 0.05615123 0.08772276]\n [0.11425319 0.11972933 0.07626663 0.07964257 0.13900935 0.07341916\n  0.14334267 0.06359468 0.09837501 0.09236741]\n [0.07942158 0.11344152 0.06580648 0.09634497 0.0865829  0.19479548\n  0.14640439 0.08315988 0.06000471 0.0740381 ]\n [0.06957166 0.08008955 0.16769526 0.09059256 0.12340536 0.0564848\n  0.14788859 0.07461858 0.1285065  0.06114715]\n [0.08989897 0.10519365 0.06277129 0.14892426 0.07859851 0.13225937\n  0.08175127 0.09402388 0.10732935 0.09924946]\n [0.07842674 0.10502722 0.12101726 0.09574771 0.08953624 0.11881725\n  0.0948318  0.11228469 0.06729214 0.11701894]\n [0.07489806 0.07249387 0.06815842 0.09543253 0.13977868 0.12008132\n  0.08794038 0.11981634 0.14222374 0.07917667]\n [0.0924027  0.10030761 0.06688511 0.15020262 0.10280693 0.07423968\n  0.1164472  0.09738419 0.07012946 0.1291945 ]\n [0.0822077  0.05207327 0.13148192 0.17205891 0.1219678  0.08772932\n  0.07167139 0.0870804  0.07357471 0.12015457]\n [0.08198264 0.12858848 0.05631431 0.11107446 0.12288436 0.167559\n  0.11583979 0.10139823 0.06509176 0.04926697]]\n32/32 [==============================] - 1s 21ms/step - loss: 0.4745 - accuracy: 0.8400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 0.9518 - accuracy: 0.6927\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual corrected self-training:\n63/63 [==============================] - 2s 22ms/step - loss: 1.4284 - accuracy: 0.8355\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 1.9160 - accuracy: 0.7820\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.1740 - accuracy: 0.7670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.6550 - accuracy: 0.7335\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.5073 - accuracy: 0.7275\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.9937 - accuracy: 0.6370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.9667 - accuracy: 0.6280\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.9629 - accuracy: 0.6255\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.3987 - accuracy: 0.5665\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.6399 - accuracy: 0.5520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.3823 - accuracy: 0.5504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Direct train on target:\n63/63 [==============================] - 2s 21ms/step - loss: 0.7286 - accuracy: 0.7890\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual self-training:\n63/63 [==============================] - 2s 21ms/step - loss: 1.4278 - accuracy: 0.8320\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.2245 - accuracy: 0.7750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.3663 - accuracy: 0.7000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.7962 - accuracy: 0.7175\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.3785 - accuracy: 0.6670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.5629 - accuracy: 0.6360\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.2019 - accuracy: 0.5735\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.2963 - accuracy: 0.5945\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.3175 - accuracy: 0.5220\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.3410 - accuracy: 0.4820\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.4112 - accuracy: 0.4336\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nSource model acc on target: 0.6927318572998047\ngradual self training accuracies: 0.43358394503593445\ngradual labelshift corrected self training accuracies: 0.5503759384155273\noracle accuracy: 0.7889724373817444\n[[0.1        0.1        0.1        0.1        0.1        0.1\n  0.1        0.1        0.1        0.1       ]\n [0.08570573 0.05079065 0.08367376 0.14602081 0.08245794 0.0709138\n  0.13036106 0.13105562 0.10640232 0.11261831]\n [0.17270834 0.08159712 0.10148766 0.08319677 0.06910194 0.0866457\n  0.13387543 0.09986543 0.0964511  0.07507051]\n [0.10343232 0.10613562 0.12692388 0.17805097 0.07998786 0.05114076\n  0.08829578 0.06823454 0.1279616  0.06983667]\n [0.1106444  0.05678946 0.0777963  0.0667466  0.12010167 0.0503353\n  0.14775626 0.15152317 0.09878214 0.11952469]\n [0.06311265 0.12109113 0.14522316 0.10097319 0.0696533  0.06685588\n  0.11825313 0.09129506 0.13947654 0.08406596]\n [0.0688698  0.06223292 0.08825178 0.15119618 0.08433587 0.13483986\n  0.08491825 0.08164785 0.16791684 0.07579064]\n [0.10212839 0.11595063 0.11490351 0.0834416  0.11602435 0.09066283\n  0.12327077 0.07202821 0.07483968 0.10675003]\n [0.05917939 0.0846331  0.09561862 0.09950004 0.15361038 0.09914002\n  0.10865063 0.05661026 0.12483815 0.1182194 ]\n [0.14753516 0.05618541 0.09280636 0.08444427 0.10659423 0.09531823\n  0.13809806 0.09248699 0.06895003 0.11758126]\n [0.14170229 0.09364371 0.12900464 0.08554079 0.10592609 0.06364698\n  0.14720354 0.13239098 0.04189885 0.05904213]\n [0.07404876 0.1522726  0.07664036 0.09422211 0.13450734 0.11689004\n  0.06151848 0.07084803 0.13813325 0.08091903]]\n32/32 [==============================] - 1s 22ms/step - loss: 0.5356 - accuracy: 0.8330\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 1.0286 - accuracy: 0.6829\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual corrected self-training:\n63/63 [==============================] - 2s 22ms/step - loss: 1.9266 - accuracy: 0.7870\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 2.1983 - accuracy: 0.7625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 3.2278 - accuracy: 0.7005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.6483 - accuracy: 0.5755\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.3030 - accuracy: 0.6055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 5.0985 - accuracy: 0.5595\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.3580 - accuracy: 0.5345\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.8653 - accuracy: 0.5090\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 6.3191 - accuracy: 0.4720\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 6.5738 - accuracy: 0.4610\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 5.4808 - accuracy: 0.4389\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Direct train on target:\n63/63 [==============================] - 2s 22ms/step - loss: 0.7219 - accuracy: 0.7926\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual self-training:\n63/63 [==============================] - 2s 22ms/step - loss: 2.0537 - accuracy: 0.7830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 2.2099 - accuracy: 0.7715\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 2.7631 - accuracy: 0.7325\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.8031 - accuracy: 0.6410\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.2159 - accuracy: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.8027 - accuracy: 0.6430\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.3216 - accuracy: 0.5850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.6667 - accuracy: 0.5655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.9334 - accuracy: 0.5625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 5.7691 - accuracy: 0.5180\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 4.3091 - accuracy: 0.5120\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nSource model acc on target: 0.6828657388687134\ngradual self training accuracies: 0.5120240449905396\ngradual labelshift corrected self training accuracies: 0.43887776136398315\noracle accuracy: 0.7925851941108704\n[[0.1        0.1        0.1        0.1        0.1        0.1\n  0.1        0.1        0.1        0.1       ]\n [0.13415083 0.08370567 0.11336095 0.08661662 0.08714763 0.10707089\n  0.08212533 0.13602155 0.12223853 0.04756199]\n [0.07894945 0.11649861 0.10734247 0.10951844 0.09887928 0.05855526\n  0.07068912 0.1417457  0.13312611 0.08469556]\n [0.05706734 0.12865142 0.10499114 0.12682488 0.09829709 0.05922464\n  0.09717239 0.11021248 0.12027155 0.09728706]\n [0.07368407 0.13975067 0.0867826  0.05573682 0.0660672  0.06442276\n  0.11537439 0.13693527 0.16098599 0.10026024]\n [0.07604192 0.11476754 0.07005924 0.09775184 0.08982744 0.09348434\n  0.06045351 0.07480668 0.09239475 0.23041276]\n [0.10281485 0.14372142 0.0960326  0.0879143  0.05564408 0.07973614\n  0.12163065 0.10218899 0.08264154 0.12767542]\n [0.10409322 0.04352452 0.11907766 0.11087183 0.13858489 0.13074412\n  0.07199658 0.10643742 0.11360023 0.06106953]\n [0.11861399 0.0793103  0.07179704 0.07303581 0.09952601 0.0913581\n  0.0934337  0.10464882 0.17859163 0.08968459]\n [0.14927699 0.08324501 0.09471061 0.10072956 0.11646766 0.11530382\n  0.08959561 0.06255948 0.1139135  0.07419776]\n [0.09150184 0.08265085 0.12566285 0.09050114 0.11053482 0.09694263\n  0.09623489 0.12789707 0.08940685 0.08866707]\n [0.06032643 0.1528049  0.16325247 0.08456175 0.12218942 0.07924859\n  0.09474221 0.11336869 0.05972559 0.06977995]]\n32/32 [==============================] - 1s 22ms/step - loss: 0.6096 - accuracy: 0.8070\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 1.1914 - accuracy: 0.6120\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual corrected self-training:\n63/63 [==============================] - 2s 22ms/step - loss: 1.6207 - accuracy: 0.8135\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 2.2686 - accuracy: 0.7685\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 2.2982 - accuracy: 0.7790\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 2.4622 - accuracy: 0.7185\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 2.3222 - accuracy: 0.7470\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 3.1254 - accuracy: 0.7010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 3.1660 - accuracy: 0.6620\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.1886 - accuracy: 0.5825\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.0039 - accuracy: 0.6115\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.7337 - accuracy: 0.5580\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.5929 - accuracy: 0.5228\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Direct train on target:\n63/63 [==============================] - 2s 22ms/step - loss: 0.6553 - accuracy: 0.7900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual self-training:\n63/63 [==============================] - 2s 22ms/step - loss: 1.5462 - accuracy: 0.8195\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 2.1602 - accuracy: 0.7790\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 2.3424 - accuracy: 0.7625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 28ms/step - loss: 2.8386 - accuracy: 0.7285\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 2.4721 - accuracy: 0.7560\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 3.3803 - accuracy: 0.6730\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.4489 - accuracy: 0.6740\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 4.2553 - accuracy: 0.5565\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.5313 - accuracy: 0.5945\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 5.3060 - accuracy: 0.5260\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.1051 - accuracy: 0.4907\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nSource model acc on target: 0.6120300889015198\ngradual self training accuracies: 0.4907268285751343\ngradual labelshift corrected self training accuracies: 0.5228070020675659\noracle accuracy: 0.7899749279022217\n[[0.1        0.1        0.1        0.1        0.1        0.1\n  0.1        0.1        0.1        0.1       ]\n [0.08668893 0.09949777 0.10025054 0.0343174  0.13488107 0.07873592\n  0.12854359 0.05441115 0.1832596  0.09941403]\n [0.08616431 0.09205976 0.09069917 0.1460231  0.10413179 0.12455759\n  0.07266055 0.07056697 0.12242824 0.09070851]\n [0.08322382 0.06407008 0.16651145 0.06981556 0.09211077 0.11947248\n  0.07665868 0.10075451 0.10811773 0.11926493]\n [0.1107311  0.09987887 0.08586427 0.11892374 0.0573152  0.18524369\n  0.06160892 0.10361851 0.0542751  0.12254059]\n [0.15081102 0.11143068 0.09285653 0.12701891 0.09603149 0.07807787\n  0.07831701 0.07022729 0.06819162 0.12703759]\n [0.10808499 0.09771191 0.11886582 0.11207543 0.12629425 0.07538336\n  0.14990742 0.06117261 0.08902374 0.06148047]\n [0.09101871 0.09555258 0.13281828 0.06933492 0.11376176 0.11845029\n  0.09264372 0.13933365 0.06554626 0.08153983]\n [0.08409573 0.06905339 0.03665494 0.1643837  0.10203285 0.12520292\n  0.11307834 0.10712836 0.07839891 0.11997087]\n [0.06615078 0.13343254 0.13193342 0.09198079 0.12973437 0.08642538\n  0.06100027 0.13371299 0.0683769  0.09725258]\n [0.09249256 0.04216647 0.06765804 0.0953588  0.24734809 0.04872729\n  0.1347748  0.11097928 0.06347596 0.09701872]\n [0.06895183 0.12617153 0.07602516 0.05083577 0.13467683 0.08400298\n  0.10321354 0.0883451  0.13733828 0.13043898]]\n32/32 [==============================] - 1s 27ms/step - loss: 0.5898 - accuracy: 0.7970\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 2s 27ms/step - loss: 0.9755 - accuracy: 0.6812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual corrected self-training:\n63/63 [==============================] - 2s 22ms/step - loss: 1.7759 - accuracy: 0.8030\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 1.9544 - accuracy: 0.7875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.0476 - accuracy: 0.7115\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.0769 - accuracy: 0.7005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 3.7463 - accuracy: 0.6530\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.1088 - accuracy: 0.6075\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.2845 - accuracy: 0.5870\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.0217 - accuracy: 0.5375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 5.7674 - accuracy: 0.4950\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 6.4387 - accuracy: 0.4785\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 21ms/step - loss: 4.0136 - accuracy: 0.5393\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Direct train on target:\n63/63 [==============================] - 2s 22ms/step - loss: 0.5805 - accuracy: 0.8100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\n\n Gradual self-training:\n63/63 [==============================] - 2s 22ms/step - loss: 1.7554 - accuracy: 0.8070\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 1.8980 - accuracy: 0.7940\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 23ms/step - loss: 2.7466 - accuracy: 0.7320\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 2.6480 - accuracy: 0.7295\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.1180 - accuracy: 0.7005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.2238 - accuracy: 0.6825\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 3.6339 - accuracy: 0.6585\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.0884 - accuracy: 0.6105\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.7084 - accuracy: 0.5770\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 4.9788 - accuracy: 0.5495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n63/63 [==============================] - 1s 22ms/step - loss: 2.7960 - accuracy: 0.6050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nSource model acc on target: 0.6812030076980591\ngradual self training accuracies: 0.6050125360488892\ngradual labelshift corrected self training accuracies: 0.5393483638763428\noracle accuracy: 0.8100250363349915\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635993851299
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copied from logs or other runs\n",
        "res_nols = np.array([0.656499981880188, 0.4894999861717224, 0.789])\n",
        "\n",
        "res_alpha9 = np.array([[0.592574  , 0.37782237, 0.49473158, 0.76417464],\n",
        "       [0.66332668, 0.50851703, 0.47044089, 0.77705413],\n",
        "       [0.63176352, 0.32615229, 0.43136272, 0.79058117],\n",
        "       [0.69909728, 0.57673019, 0.54964894, 0.82597792],\n",
        "       [0.64794385, 0.48545638, 0.4458375 , 0.76379138],\n",
        "       [0.62324649, 0.56162328, 0.48547095, 0.77755511],\n",
        "       [0.69273186, 0.43358395, 0.55037594, 0.78897244],\n",
        "       [0.68286574, 0.51202404, 0.43887776, 0.79258519],\n",
        "       [0.61203009, 0.49072683, 0.522807  , 0.78997493],\n",
        "       [0.68120301, 0.60501254, 0.53934836, 0.81002504]])\n",
        "\n",
        "res_alpha3 = np.array([[6.696741580963134766e-01, 3.799498677253723145e-01, 5.127819776535034180e-01, 7.614035010337829590e-01],\n",
        "[6.760280728340148926e-01, 6.193580627441406250e-01, 4.994984865188598633e-01, 8.239719271659851074e-01],\n",
        "[5.894736647605895996e-01, 2.330827116966247559e-01, 4.250626564025878906e-01, 8.005012273788452148e-01],\n",
        "[6.158475279808044434e-01, 4.082246720790863037e-01, 3.751253783702850342e-01, 7.903711199760437012e-01],\n",
        "[5.964912176132202148e-01, 4.000000059604644775e-01, 5.333333611488342285e-01, 7.904762029647827148e-01],\n",
        "[6.060150265693664551e-01, 5.157894492149353027e-01, 5.107769370079040527e-01, 8.190476298332214355e-01],\n",
        "[6.872180700302124023e-01, 4.130325913429260254e-01, 5.749373435974121094e-01, 7.869673967361450195e-01],\n",
        "[6.355889439582824707e-01, 4.992481172084808350e-01, 4.421052634716033936e-01, 7.839599251747131348e-01],\n",
        "[6.242485046386718750e-01, 5.581162571907043457e-01, 6.112224459648132324e-01, 7.700400948524475098e-01],\n",
        "[6.621553897857666016e-01, 4.451127946376800537e-01, 5.228070020675659180e-01, 7.689223289489746094e-01]])\n",
        "\n",
        "res_alpha1 = np.array([[0.6447895765304565,0.34769538044929504,0.4393787682056427,0.8191382884979248],\n",
        "                [0.6889111995697021,0.26693427562713623,0.2599096894264221,0.7651781439781189],\n",
        "                [0.6292585134506226,0.26002004742622375,0.2760521173477173,0.8151302337646484],\n",
        "                [0.6175438761711121,0.33734336495399475,0.4045112729072571,0.826065182685852],\n",
        "                [0.6487975716590881,0.4759519100189209,0.3491984009742737,0.7414829730987549],\n",
        "                [0.6508015990257263,0.5285571217536926,0.5536072254180908,0.851703405380249],\n",
        "                [0.6295739412307739,0.5298245549201965,0.4521303176879883,0.7538847327232361]])\n",
        "\n",
        "\n",
        "res_alpha9_mean = np.mean(res_alpha9, axis=0)\n",
        "res_alpha9_std = np.std(res_alpha9, axis=0)\n",
        "\n",
        "res_alpha3_mean = np.mean(res_alpha3, axis=0)\n",
        "res_alpha3_std = np.std(res_alpha3, axis=0)\n",
        "\n",
        "res_alpha1_mean = np.mean(res_alpha1, axis=0)\n",
        "res_alpha1_std = np.std(res_alpha1, axis=0)"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635996680156
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"label shift + gradual x|y rotation up to 30 degrees\")\n",
        "print(\"label shift (Dirichlet alpha)  |    src model   |   self train    | self train corrected |   oracle\")\n",
        "print(f\"               none            |    {res_nols[0]:.4f}      |     {res_nols[1]:.4f}      |                      |  {res_nols[2]:.4f}\")\n",
        "print(f\"                9              |{res_alpha9_mean[0]:.4f} ({res_alpha9_std[0]:.4f}) | {res_alpha9_mean[1]:.4f} ({res_alpha9_std[1]:.4f}) |    {res_alpha9_mean[2]:.4f} ({res_alpha9_std[2]:.4f})   | {res_alpha9_mean[3]:.4f} ({res_alpha9_std[3]:.4f})\")\n",
        "print(f\"                3              |{res_alpha3_mean[0]:.4f} ({res_alpha3_std[0]:.4f}) | {res_alpha3_mean[1]:.4f} ({res_alpha3_std[1]:.4f}) |    {res_alpha3_mean[2]:.4f} ({res_alpha3_std[2]:.4f})   | {res_alpha3_mean[3]:.4f} ({res_alpha3_std[3]:.4f})\")\n",
        "print(f\"                1              |{res_alpha1_mean[0]:.4f} ({res_alpha1_std[0]:.4f}) | {res_alpha1_mean[1]:.4f} ({res_alpha1_std[1]:.4f}) |    {res_alpha1_mean[2]:.4f} ({res_alpha1_std[2]:.4f})   | {res_alpha9_mean[3]:.4f} ({res_alpha9_std[3]:.4f})\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "label shift + gradual x|y rotation up to 30 degrees\nlabel shift (Dirichlet alpha)  |    src model   |   self train    | self train corrected |   oracle\n               none            |    0.6565      |     0.4895      |                      |  0.7890\n                9              |0.6527 (0.0349) | 0.4878 (0.0832) |    0.4929 (0.0437)   | 0.7881 (0.0183)\n                3              |0.6363 (0.0335) | 0.4472 (0.1023) |    0.5008 (0.0667)   | 0.7896 (0.0195)\n                1              |0.6442 (0.0214) | 0.3923 (0.1087) |    0.3907 (0.0962)   | 0.7881 (0.0183)\n"
        }
      ],
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635997473592
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "src_model_mean = np.array([res_nols[0],res_alpha9_mean[0], res_alpha3_mean[0], res_alpha1_mean[0]])\n",
        "src_model_sd = np.array([0, res_alpha9_std[0], res_alpha3_std[0], res_alpha1_std[0]])\n",
        "self_mean = np.array([res_nols[1],res_alpha9_mean[1], res_alpha3_mean[1], res_alpha1_mean[1]])\n",
        "self_sd = np.array([0, res_alpha9_std[1], res_alpha3_std[1], res_alpha1_std[1]])\n",
        "selfco_mean = np.array([res_nols[1],res_alpha9_mean[2], res_alpha3_mean[2], res_alpha1_mean[2]])\n",
        "selfco_sd = np.array([0, res_alpha9_std[2], res_alpha3_std[2], res_alpha1_std[2]])\n",
        "tar_mean = np.array([res_nols[2],res_alpha9_mean[3], res_alpha3_mean[3], res_alpha1_mean[3]])\n",
        "tar_sd = np.array([0, res_alpha9_std[3], res_alpha3_std[3], res_alpha1_std[3]])\n",
        "\n",
        "x_labels = [\"No LS\", \"9\", \"3\", \"1\"]\n",
        "plt.plot(x_labels,src_model_mean,label=\"trained on src\")\n",
        "plt.fill_between(x_labels,(src_model_mean-src_model_sd), (src_model_mean+src_model_sd), color='b', alpha=.1)\n",
        "plt.plot(x_labels,self_mean, label=\"self-train\")\n",
        "plt.fill_between(x_labels,(self_mean-self_sd), (self_mean+self_sd), color='orange', alpha=.1)\n",
        "plt.plot(x_labels,selfco_mean, label=\"self-train correct\")\n",
        "plt.fill_between(x_labels,(selfco_mean-selfco_sd), (selfco_mean+selfco_sd), color='green', alpha=.1)\n",
        "plt.plot(x_labels,tar_mean, label=\"trained on target\")\n",
        "plt.fill_between(x_labels,(tar_mean-tar_sd), (tar_mean+tar_sd), color='red', alpha=.1)\n",
        "plt.title(\"Per-step arbitrary label (Dirichlet) shift + gradual x|y shift\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABRPklEQVR4nO2deZwcZZ3/39+q7p6eM5MLSDIJRBIEATkMBIwQFwSCBwgKyyK62V2NKCjuriy4HuuB/nBRVnQRfyCIB4ocPw5XrnVZuUESCBIOEy7NhCvXJHN3d9X398dT1VNd0z3TM+mZ6el53nlNuuqpp556qqv6833q+3zreURVsVgsFkvt4kx0BSwWi8Uytliht1gslhrHCr3FYrHUOFboLRaLpcaxQm+xWCw1jhV6i8ViqXGs0I8DInKtiFw0xPYuEXnLeNZpKERkpYg8WGber4rIL0Z5nCH3FZE6EXlWROaMoMyPiMg9w+QZ9vsWkb1EREUkUWL7rpx3nYg8LyKzR7HvcPX6VxH5cWT9FBHZGJzzIaOpbzUgIu8WkfYKlfV7Efn4KPeteDx6cD0XldhWcD+LyDIR2RBczw+We4wxF3oReUVEeoOKvRGIXtMYH3PUF3IiUNUmVX0JhjcKU4xVwP2q+hrkv5uMiHQGf+tE5P+IyLRwB1W9TlWPH6rQ6Pc9HsTvR1XtB64BLqz0sVT1W6oavfe/A5yrqk3A9qGMhKX6KHI/fx34z+AevnUoIxFlvFr0HwhutEOBJcCXRrKzGCbl04eIuBUub8Q/0kn8wz4b+Hks7d9VtRmYDfwdcATwkIg0DldYlX0PvwT+VkTqxvg4ewLPjGbH4OnhlcpWp+quw2RjVNdzXMVTVTcBdwIHAIjIESLysIh0iMhTIvLuMG/QCvqmiDwE9AAFj9oikhaRX4jI1mD/x0VkdxH5JnAU8J/BU8R/Bvn3FZH/FpFtIvInETk9Uta1IvKjYHuniNwnInuWOg8RuVFEXheRHSJyv4jsHyvrChG5Q0S6gb8KNs0qVX5olUVkFfAR4F+Cuv8m2P6KiFwgIn8EukUkISIXisiLQXnPisgpkfJWishDIvIfIrIV+Hpw3gdG8uwmIj3luA9E5LLg8X+niKwRkaNiWdIi8uugLk+IyEGRfeeKyM0isllEXhaRzw53vGC/BZhr/lix7arap6qPAycBMzGiP8jtFHy354jIBmBDJG1RsFwvIt8VkT8H1/NBEamPHOojIvIXEdkiIl8cor5F7+VS96OqtgPbMYaqWHmHi8jq4Dt/Q0QujWUpWi8JXEpi3ENdgAs8JSIvAvcH2TqCuhxZ6nxGiojMFJHfBPV9XEQuKuM6lLyvgutyrYhsF5FngcNixytoyUrkSVhEpovIfwX33PZgua3M87hDRL4bWb9eRK4pki81kt9U8Pu+L7jHtojIr2NZ3iPGJdMhIpeLiAT75e/n4Bq+BfhNcP0eCfZ9Klj/65Inpqpj+ge8ArwnWJ6PsUbfAOYBW4H3YgzOccH67CDv74G/APsDCSAZK/eTwG+ABszN/A6gJbLvxyN5G4GNGDFIAIcAW4C3BduvBTqBo4E64DLgwSHO6e+B5iDv94C1kW3XAjuAZcF5pYcrH1BgUWT/i4p8h2uD768+SDsNmBsc46+BbmBOsG0lkAM+E5xvPfBD4NuRMs8DflPi/FbG6ncWRkwTwD8DrwPpYNtXgSzwYSAJfB54OVh2gDXAV4AU5iZ9CTghsu8vStThfcAzsbRB302Q/jPg1yXqrsB/AzMi3130+748uF/mYe6jdwbXaK8g31XB93cQ0A/sF6875d3LHy9S79uBz5Y4/0eAjwbLTcARwXLZ9SpyruG+iTJ/u3sBr5SZ9/rgrwF4G+b3Ntx1GOq+uhh4IMg/H1gHtBc7r/i9EZT5oaAuzcCNwK2RvEWvR7BtD+BN4BhMo+sloDl63MjySH5TvwK+yIAmvCt2Lv8FtAILgM3AihL38ysEelrseyj1N14t+ltFpAN4ELgP+BbmIt+hqneoqq+q/w2sxvxYQq5V1WdUNaeq2ViZWcwFXaSqnqquUdWdJY7/fswN+5OgrCeBmzFiGfJbVb1fjf/0i8CRIjK/WGGqeo2qdgZ5vwocJBE/MXCbqj4UnFffSMsvwfdVdaOq9gZ1uFFVXw2O8WtMK+nwSP5XVfUHwfn2Aj8F/iZsKQAfZbBbpCiq+gtV3RqU9V2MEL41kmWNqt4UXKNLMTfyEZhW2GxV/bqqZtT4xa8CzijjsK0Y41gOr2IEoRT/R1W3hd9diBh34N8D56nqpuA+eji4RiFfU9VeVX0KeAojrHHKuZeL0Yk5z2JkgUUiMktVu1T10dj2cuo1LohxT34I+DdV7VHVZzH3W5yC6zDMfXU68M0g/0bg++XWJyjz5qAuncA3geVl7vs68Kmg/pcBHwvKKMZIflNZjNtlrpqn0Xiww8Wq2qGqfwH+Fzi4nPqWy3gJ/QdVtVVV91TVTwcXek/gtOBRpSMwBO8CohEWG8OF4NEk/FuA+ULvBq4XkVdF5N9FJFni+HsCS2PH+gjGeg86lqp2AdswLeYCRMQVkYvFuE12YiwswKxiZY20/CEoKFNEPiYiayPnc8BQdVDVxzAusHeLyL7AIkyLclhE5PMi8lzw2NkBTCt1LFX1gXbMue0JzI197/8K7F7GYbdjWmPlMA/zfZai2PUAcw5p4MUh9n09styDaV3HKedeLkYz0FFi2z8A+wDPB66Q94+iXiNGRM6MnMMfgQXR8wp+e3FmY1rl0e95yN9AcKyh7qu5sfx/HsE5NIjI/xXjjtuJcVm1Svn9Zb/BPN39qYgg5xnhb+pfAAH+ICLPiMjfx7aPyfUMmchOkY3Az1X1E0PkyYcyqenMjfM14GsishdwB/An4OrofpFj3aeqxw1xrHzrWkxU0AxMSzHOmcDJwHswIj8NI0oSyVMsBKvc8kuFb+XTxfj3rwKOBR5RVU9E1pZRh59iWp+vAzdFnjZKEvhN/yU41jOq6otI/Hyj5+YAbZhzywEvq+ri4Y5ThD8CC0Ukoaq5IerXhLkW3xyirFLf6RagD9gb0yoeLcPdy6WOvx/w3WIbVHUDprXoAKcCN4nIzF2o41D1iB73l5iOYoLf1e9Vda9hdtuMudZtwPogrdjTavQeHu6+eo0BVy8Yl0aUHoxrJmQPTAMDjBvorcBSVX1dRA4GnqTwnh2KbwLPYe6/v1HVXw2Rt6zfVPCk8AkAEXkX8DsRuV9VXyizTrvEREay/AL4gIicELSS02JiZcvtNPkrETkwsNI7MY9GfrD5DQo7b/8L2EdEPioiyeDvMBHZL5LnvSLyLhFJYfoQHg0eGeM0Y3yiWzE32rfKPN9yy4/XvRiNmB/NZgAR+TuCDu5h+AVwCubG/FmZ9W7G/Ig3AwkR+QrQEsvzDhE5VUw0xecw38+jwB+ATjEdyfXBdT5ARA5jGNR0Vr5AoTsqj5jOxncAt2IM7U/KPJ/oMXxMmOOlYjqNXRE5UkYeCTPcvTzomorIPIyxj7tkwu1nicjsoI4dQbJfLO8I2ByUUdF3NlTVA/4f8NWgNb0v8LFhdhvuvroB+IKYjtU2TH9TlLXAmcH3vYJC10wz0IvpdJ4B/Fu55yIiR2P68j4G/C3wg+BalaKs35SInBa5H7Zjfr+7ej2hPL2YOKEPRO5kzKP8Zkyr6PwR1GkP4CaMyD+H8f2H/rHLgA+L6XH/fuBjOx7jG34VY32/jfEJhvwSc0Nsw3TsnlXiuD/DPEZuAp6lxA+1COWWfzXwtuAx+dZiGQIf6HcxHXZvAAcCDw1XgeA7fwJzkz1QZr3vBu7CtNT+jGkBxw3UbZgO4e0YP+WpqpoNBOD9GH/jy5gW9I8xT0Hl8H+D8qL8i4h0YgztzzCdve9U1e4yy4zzeeBp4HHMtfk2I/xdlHEvF9yPQdqZwE9j/QFRVgDPiImcuQw4I97HMFJUtQfTWn0ouL+KRvyMknMx1/V1zO/wVxiDX4rh7quvBekvA/cw2Pd9HvABjBH8CMbgh3wP01G9BfP7vKucExCRFsw9dW7QZ/MA5vf4ExEp+jQwgt/UYcBjwfW8HdMvVIl3Ob4K/DS4nqeXyiSqwz7N1Twici2mR39E8f2TETGhYq9OhnMNWtZPAsdq8NJULRCc11PA0ar65kTXZywQkW8De6jq3050XSqJiKiqSiyt6n9T9sWFKUTgcz0VE15a9QSt3bdNdD0qTXBe+050PSpJ4K5JYZ6ODsN0Jk+at9NHy2T5TU3Kt00tI0dEvoGJRb5EVV+e6PpYao5mjJ++G/g1xrV424TWaGz4WrgwmX5T1nVjsVgsNY5t0VssFkuNM2E++lmzZulee+01UYe3WCyWScmaNWu2qOqIhrieMKHfa6+9WL169UQd3mKxWCYlIlL2W8Ih1nVjsVgsNY4VeovFYqlxrNBbLBZLjWOF3mKxWGocK/QWi8VS41iht1gslhrHCr3FYrHUOFboLRaLpcaxo1daLBZLpfH9gT/PM5+53MBfYyM0VXS2wCGxQm+xWCzloDog2uGn70MmMyDgmYzZ5nkQzlWiOrDsupDNguNYobdYLJZxISre8dZ3KOChePv+gGhHxdtxBv4SCUilBrZVCVboLRZLbaFaKNrFxDubNZ9R8Y4SFW/XrUrxHglW6C0WS/UTF+9wORTtULizWbMtvq+IEW0RI9yOA/X1k1q8R4IVeovFMjGE4h1vfUf93bncQFq4T1Sc4+KdTptPSwFW6C0WS+UoJt6+X9jizmYLxTtOKN5Rt0k6Pb7nUWNYobdYLMNTqsMyFPCww7KUeIfCbcV7QrBCb7FMVYp1WHre4A7LXK7QZRIuR8Xbcax4VzFW6C2WclCdvOueN7jDMu7ztuJd05Ql9CKyArgMcIEfq+rFse0LgJ8CrUGeC1X1jspW1VIVhI/voS826pONiotqZdfjkRTDrZdT/kjLi3YCVtv6UMTFO5m04j3FGFboRcQFLgeOA9qBx0XkdlV9NpLtS8ANqnqFiLwNuAPYawzqa9kVQrErJdZR32v0le3otrCcuMgUSxvpepxdLS+6HrZWK1k/i2WSUE6L/nDgBVV9CUBErgdOBqJCr0BLsDwNeLWSlbQElGpFR8fViIp0+BntSIuWVUzIwoiHaNxxlb7tZ7FYyqMcoZ8HbIystwNLY3m+CtwjIp8BGoH3FCtIRFYBqwAWLFgw0rpOfkqJdPg5lEhHoxlKiXQo0FGRDv2sxVq0FotlEKoKuRwa/mWzwWcOzWVjaVk055n0ItsJ07I51AvK6Oul+bjjaDjmmHE7p0p1xv4NcK2qfldEjgR+LiIHqGqBo1NVrwSuBFiyZIkWKad6Gc7tEdwcg0Q6/BvO5wuFAh31qyYSUFdnhdoyaVHfHySQDCGQBeLqFRHbIp948e2R/aJp8fXYMUuGiFYASSaRRIK6ffahYcyOMphyhH4TMD+y3hakRfkHYAWAqj4iImlgFvBmJSoZRUOhjbZQRZDhRHAot0c4sFH4N5zboxTW7TGl0ND4R/7iaWXnifZ/+Iqi+WWCZY0sF+QpVnaQVz1/kFASF8pBAhkVxagQexExLJI3L6qDBbSs389ocBwkkcgLaMFy/jOBJJJIXR1OY+PAevwznze+XpiXcN2Nby927CTiukgyCa5rdKq3F1pahj+3ClKO0D8OLBaRhRiBPwM4M5bnL8CxwLUish+QBjZXsqIh2665hje/893SGeIuimBdhtpmNhbuLwICUiI9ml+kSJ78IQanDTpuwf4mTQqOFckX5B10zNhyQdmxOks8rcBgDj5WNN9QdTYiRPCjVhPYor5JUwX1gzQtSNdieSLCp1ERHG6/ksLnB0XoEHUamWDXLHHBHEJAnYbGSJqLJJIwSDhjojpIIIsLJYFADimgrjvR39akYFihV9WciJwL3I0JnbxGVZ8Rka8Dq1X1duCfgatE5B8xP6GVqmPzS6g/9B3MOvtsyPTHXCPmx5z/8RMePiJWCoig8cZ1WFUNhCAUrHx60DrSgeV8eig6+dYVBfuEaQNfR6TsSFkaT4scf1CdImUV1Cl67Hidixw/30IMv65Q0ML9iO0bFT0GHwskP86IyMAyIogj5A1EsCzBspAonWeI/fLGp4w85jhBmuxi2ZEywvJGU3bJOpVTdjRPvK6x/SSZHCyUiUCYY+kkEsM/HVsmHTJGejwsS5Ys0dWrV1euwHj0STxsMB4yGL7tV2qwpDAt9JPH/eZhmsVisYyE0HUze/aodheRNaq6ZCT71M6bsSJmDI3RPMoVMw7xkMViHa3F/I5Rg1HMQET99xaLxTIO1I7Q7wqhCI+UeCRO3FBEI2/ixmKol4/COsXDJEdbT4vFMqWxQr8rRFvrI6VY9M9QkwlH56aMG4foerQ+cTeTNRIWy5TECv1EsauuplJ9EuHTQ/xJIu5qGi6OP/4kYV1NFsukxQr9ZCRsmY/USMRdTcP1R0SNRrG5NYv1R4wHky20caLrWywEN9p/VCwE2FJTWKGfSlTC1VSqTyJ0L00Uk02oxrO+xYx51E0YPgkWM0hDRaNZAzJpsEJvKY/Q1WSpXYq9FBYa83hasb9iBmQkwwmUMiCljIc1IGVjhd5isRjGSjzLMR6lDEh0rChrQEaNFXqLxTK2VKMBiT59DGdASoVATyIDYoXeYrFMTibSgAwVzFAsVNrzCssfZ9G3Qm+xWCxRxsOAjPM7LVboLRaLZTyYQPeNfVXSYrFYahwr9BaLxVLjWKG3WCyWGscKvcVisdQ4VugtFoulxrFCb7FYLDWOFXqLxWKpcazQWywWS41jhd5isVhqHCv0FovFUuNYobdYLJYaxwq9xWKx1DhW6C0Wi6XGsUJvsVgsNU5ZQi8iK0TkTyLygohcWGT7f4jI2uBvvYh0VLymFovFYhkVw45HLyIucDlwHNAOPC4it6vqs2EeVf3HSP7PAIeMQV0tFovFMgrKadEfDrygqi+paga4Hjh5iPx/A/yqEpWzWCwWy65TjtDPAzZG1tuDtEGIyJ7AQuDeXa+axWKxWCpBpTtjzwBuUlWv2EYRWSUiq0Vk9ebNmyt8aIvFYrEUoxyh3wTMj6y3BWnFOIMh3DaqeqWqLlHVJbNnzy6/lhaLxWIZNeUI/ePAYhFZKCIpjJjfHs8kIvsC04FHKltFi8VisewKwwq9quaAc4G7geeAG1T1GRH5uoicFMl6BnC9qurYVNVisVgso2HY8EoAVb0DuCOW9pXY+lcrVy1LNeL75s/zBv4yGfOXzZp1x4FEwvxFl0XMevgZX7ZYLGNHWUJvqX3iAu77AyIeFXKRwv1cd0CsEwlQNXn7+82yqikrRHWgjOiy45iywr9EonC5lIEIly0WS2ms0E8B4iKeyxkxzmYHRNz3jfDCgPiGIu66UF8/WOQrSWgQfL+4oYgahWKEdY0/SUTTihkIaygsUwEr9JOcYiIebYXncoUt6pDxFPFyEBlowY+G0Bj4vjnn0FBEDdhQhE8NxdxOoXEoZiDCZYulmrFCX8VE3ShxEc9kzHpcxKICVC0iPh6ErfJKGIq+vsFPE1Da7QQDrqbQQETdTsUMRdxoWCxjiRX6CSAUkGhLPNqxGRXxqDslFIZQQFIpKxKVYlcMRdQohIYifIqKP1EUc0FFDXPcQIRGY6g+CnsPWIbDCn2FKSbiUV946E6J//ijP3Yr4pOLqBEeDVFDEfafhAYiauxLEb93irmdwnpG6xxfLjetEtst44sV+hGgOtidEop4NDIl/sMMW17hD7GubmLqb6lOKmEoQsOQzRaul2MoipU3lCjv6nYYONfoOUeNQ7HlaN5i+0cN2lD7xMuPHz9el3LSRrp9vI2eFfqAqIgP1bEZv4mjralkEtLpiTsHy9QkbERMFuJPs/HleFq47nnl7T/csYYzfMUMVTnGayRlzpoFM2aMvryRMiWEvpiIR10poYhH88c7NVMpK+IWSyWY6u6c3t4BozVeTDqhf/yVbdy/fjOuI7giOI7gYP4IPtUv/HMQHBFcx3wmHLNf0nWMPzzhkHAJ8jg4Aq7j4Aaf4b5upIziaSBT8c61WCxVzaQT+if+vJ0f3PvCRFejJFHhz38WSUvE80QMV/Qznu46QxubcgxSsfVidShWp0SJcl3HIZ1waapLkE641uBZLFXEpBP6Ty7fm4+/a2/6+pVMVuntU3p6zWcmq+R8xfMVXxUfRUTBURBFMds8HcgTfuZi62E+P/KZy6/7pjNWfTyfWDk+voIX+Ywez1dieYrXyfN9MrE6FKvTcOcyESPMuSI0pBI01SVoSiVpDJYbU8ngs3C5qS5JUypID5YbUgkcaywsloow6YQejM+8sUFoRJg+bSA99MXncgN++P5+8xeGrMXLiYak1SJ+EYMwlGEbytAVMzYD+/n0ZT26Mjm6+rN0Z3J09efozmTp6s/xRmcf3ZlOujI5uvtzeMP0iAkYYxGIft4Y5D8HjEiBsQjSm+rMfolavbAWywiYlEJfiugr7ACNjYXbo0YgDIvs6zOGIN45En/LcbLiiOC4UlUXWlXpy3mBIRgwBt2BkejK5OjJ5OjKp5vP7b0ZNnZ0B/vkyHhFxnaIEbqTGlOBYYgtD3waYxE1HI2BoUklJvENYJlwVJWM55P1fDKez85uH6cuwWyS41aHavr9jzlDjaUSvqwSDavs6zOfvb2FeaOjNYZvLVrKR0SoTyaoTybYlXnGMjnzBNEdeYqIGovufmMsuqPL/Tne6OzNP3H05YYPf0i5Tv7pIm8AirmiBm0fyGP7LcaXnB8Ia84vEFnz6eWXs55Pf25gOUzv97xBafGyMkGe4crKFhls6gvvOYBPtu05bt/HlBL6oXAcE0JZjKhLKHxzMTQCPT2FcblhWGZ07BPL2JBKuMxIuMxoGP0baDnfN08PEUPQFTxlhMvF0jd29NAdefoYri/EFck/OTSW6LeIP1FEXVVNqQT1VdxvEW+1DohhKHxeXiijwlhMMMsR50yQr1Qev0KdU64jpFyHpOuQCv7MsptfbkgmSKWD9ERhnsH7OajvcGjbOAbRY4W+LOIuoThRIxCOnNjfXzjmSVhOfEwTy8SScBxa0ila0iWsfBn4qvSETxOZXN4AxJ8yKtlvEe2rCJ8m8v0TkfS6hDOEMFZOZIu1WkeDQF4Q8yKZcAvSkq5DazKRX87nTbglRHlgv7oiZdVFlk26S13CIeE4uE7lDWtvL7S0VLzYIbFCXwFC0S42tEHcJRQagf5+c8GHmnyjShtvlhiOiGmB1yXZfZRlFPZbRI1CxBWVGWwstvdk2Lh9ZP0WccJWa1wYi7VaU4nSeQrFubBVW1xQB4Q3TEs4Yl1cY4AV+jEm7hJqbh5YVi00AqFLKDQEvm/EPhz0LD7jkqV2KOy3GP0r2PF+i4znF4h4tJUcplWrO8hSOazQTyAiZnycZJHO9+iwDaFLKDQCvb0DLqHwiWAqhIpahqcS/RaW2sMKfZUS7RcIXULTIu8MxI1Af//AewPhuD3RMXui87BaLJaphRX6SUrYgi8WKRSdkcrzBoxAX9/A7Ekh8acB+xRvsdQeVuhrkDDOP3QJNTUNbIu/PRxOxN3XV+gSCrEuIYtlZIQzjYV/0YllwPzu7Hj0ljGl3FDR+NvD4bDO0Ru0Vt4etljixKeHjM4pHI+CjU73CQO/h2SycLav6IxfxfrlxhIr9JYChnt7ONovEB1LKB4qWozoLErR+U6jy9Z1ZKkkQwl2GNVWbJ+wQRQKdrkTvlfrU68VekvZDNUaCV1C0R9WfEq7XG7gBxYuh4Yj3D6SukTfP4gbjGr9wVlGR1ScS91fpRoJccGOt67jf7V4/1iht1SEsAW0qwxlKIoZjegcvqHLKUwvl/gThTUaY0ex1nXcJRJ3hcBA5FjY0IgKdvhyYSnRtpQp9CKyArgMcIEfq+rFRfKcDnwVUOApVT2zgvW0TBEqKa5DGYpwOTQM0aeMqNEItw91jPikz6WMRi0JT1ywh5qMvNjb31Ghjgp2KXdIrXxvE8WwQi8iLnA5cBzQDjwuIrer6rORPIuBLwDLVHW7iOw2VhW2WMqlkpNml/OUEX2aiD5lxNPi5RYTsaEMRiWNRtxnHV0fiqhgp1KF/uuoYMdF2wr2xFBOi/5w4AVVfQlARK4HTgaejeT5BHC5qm4HUNU3K11Ri2UiqaTRGO4pIyq6xfo1omnFDEW5aTBYsKP+67hgR8XaCvbkohyhnwdsjKy3A0tjefYBEJGHMO6dr6rqXfGCRGQVsApgwYIFo6mvxTLpqaTPv5ShiKYN5b+2gj01qFRnbAJYDLwbaAPuF5EDVbUjmklVrwSuBFiyZMlETGdqsdQUtqPYUg7l3CabgPmR9bYgLUo7cLuqZlX1ZWA9RvgtFovFMsGUI/SPA4tFZKGIpIAzgNtjeW7FtOYRkVkYV85LlaumxWKxWEbLsEKvqjngXOBu4DngBlV9RkS+LiInBdnuBraKyLPA/wLnq+rWsaq0xWKxWMpHdJjpy8aKJUuW6OrVqyfk2BaLxTJZEZE1qrpkJPvYrhyLxWKpcazQWywWS41jhd5isVhqHCv0FovFUuNYobdUDi0yK4PFYplw7DDFltGjPnj9kOuB7A7QYEB5cYO/hPl0ksFnAsQBHPNZsGzfxbdYxgor9JaR4WeNuGd3Qq4rSHTArQNJm1X1g78c+Bnwesy62TjwUaDtDjihcUgERiFhjUMZqCqeeni+l//M+TkyXoaMl6Eh2UBDsoG6RB2O2If4qYgVesvQqG/EOmy1+1mTLklwG0uMsRsK8kiOo0BgIPw+8MKRufwBgzAFjYOvPp7vmc9AxEMBz/pZsl4WT738d6OqCILjODhi/rb3bWdrz1YQaEw20pxqpj5ZT9Id54lLLROGFXrLYPwceH1Bq707EFsXnBQk6sbmmCJA4PIpl9EaB3EGjEJoGJwExQ3DKIxWmYQiHm2FR1viWT+L55upskQkfy6uuHkRL6eVnnJTgDECGS/D612voyhJN0lLqoXGVKNt7dc4VugtwXi2oa99p1lGjAi6DdXbCt5l49AP9EaMg+Y9S4WGQiL9DTEDIW5R4+AF7pRQzAsE3MuS0xy+HxgkBUURkbyIu45LfaLeCHzFvi6hLlFHXWCsPd+jo7+Drb1bEZF8az+dTOeNg6U2sEI/Vcm32juNr139oKVbB4nmia7d2DFq42CMgXoZfL8Hz8/hac58ej4ZzZDxcmT8LDk/i6+KSDIQfhdxkjhOEsdN4TpJ6p0kkog9RYxzi9p1XBqchuAUY619J0lLnW3t1wpW6KcK+VZ7b+Br7zetVSdZ3a32cURjrXBPfbJ+lkwuaz79HLmwj4IwklTz/nDXSZFw06TECVwtfuEThGYg10fQhI+5lALyTw4uEH2KCGbAFsfsKG7wWZl+h+Fa+w2JBlrqWmxrf5Jihb6W8XNG0LOd5i+cT67WW+1FKIxMMR2bOT9HJpcl42fIejlymjMuFARUQDTvC3fEIem4pBMjEDlxAjEfydNDOE1UzhiG0FDkjUO+1zUi8GGndKRjOhrOmg9xLb9VXk5rvyHVQDqRtq39SYAV+lpCNRIhszPSak+AWz/uroHxwle/oBXuqUcmlyHjm5Z4zvPIhTH+iIlMEfIC7opDKpEkLWPU0TwSRmscAtfSoH6H8NFBCPpc6sBJg5uKRSgNUaUirf0d/TtMax+hIWlb+9WOFfrJju+ZiJNsV9Bq9wJfewoSTRNdu12mMDLFiHjWy5Lxs2Q8I+SeeqYVHvZsAq44SLWJ+FgRCvVw/Q7qg5cx7jv1zBOBqhF9p840BvIvtyVLuoRcx6XeqTdFqpL1s7ze9ToIJCRBc12z8e27dbhOhWZUt+wSVugnG2Gr3eszvnav17gZHBfc9KRqtRfGh/vGleJng8gU40rxgxetAnc4IkbEHcfFFYf6RLqikSk1jThG1OOoZ+6nfCht8H06qaD1X2eEPx9xNPB9iwgpN5VvyXu+x87+nWzv2w4KDckGmutM3L5t7U8cVugnA74X+Nq7jEsGH5Cg1V6dvvZofLgXtMpDEc94OXKaZWDSG9OyFEcG3CmOQ71YER8XxAW3SMvb98xbzdmdwcOSDjwtuvXB29DugBGgeGv/ja438r79prommlJNtrU/zlihr0ZUg6EGes2PzAt8rk6iqlrt4Qs+Od+jL9dHfxERVw3cw4GIu+KScBxSUtkYccsY4LiAawQ9JPT95zrNE2X+xYPgacFJm3vUcRFJDmrtd/Z30tHXAQr1yXpa6lrMW7pO0t4PY4gV+mohbLXnugNfexYTTZGccF97XNB7A1H31IPAO+6Kg+skSDgOdUG0hqUGkTC0M9YaVzUuoGwnZDsiUUEOJNIgdbhuHfVOAiQFjkvGy/Bm95v46tvW/hhjhX4i8TIDQw14PUGiWzhA2DgSCnrWz9GX68+30k1npwMorjgknIT1jVsKCd8edmKSon4kzHdgTB4kYVr7Tj24KXygs28H23u3IwjpZJppddNIJ0wkj73Xdg0r9ONJfljfbiPuYcjfOEfIWEG3jBvhG79ObAA19cHLmhfI1MMRoV41eIEvTaavlzf7tuPj4ibqaElPozHZSDqRtq39UWCFfqyJttr93iC2ORHEMY9tq90KuqVqGTICqJ+U5kipgih+Tuns3cR2kohbRzrVwrT6GaSTTaQSdfa+LQMr9JUm3mr3s8FjbRKcsRlqwAq6pWbIRwANGAEHqPe9YH6DXjI9O3mz82UUwXHraKmfRWN6BulUM24iPTBchCWPFfpK4GcLh/VFyfva3cq02sNX+KOC3pvrJeNlCwXdcUmIawXdUltEIoBSBGZAFd/P0dn7Jtu72gGf+kQ9Lalm6uumkUq1IImGIP4/GZQxNbFCPxriU+j52aCDKVV6Mo5yiw4E3Qxl6+UFvd/LBCGL5u1PK+iWKY8Ijpuk3p2WT8p6WTb39+D37sBFaU7V05RqoM5NkXBSpuEVvgPgJIMO5No3AFboyyU+hZ4q+ck4kiNvtY9U0BsqPDa5xVKLJN1kfuYsX326vAw7ejtRVdJuipZUPQ1OkpTrmsBgUdPad+vMKK75MYBGNghctWOFvhQFk3HsMMMOEPjaR9Bqt4JusUwMTjBERkjWy7K5b6cZ3sdxaEo20pxqos51SIRjAOEPFCDBYIBuMAxE3gBMvt9nWUIvIiuAyzBvSfxYVS+ObV8JXAJsCpL+U1V/XMF6jg9FJ+NwyxpqwAq6xVLdxFv73bkedmY6Aahz62ipa6I+kabODSJ58mMAhU/wwe/YSQYGIBgELnQBVfHveVihFxEXuBw4DmgHHheR21X12VjWX6vquWNQx7Gj2GQcw0yhN5ygq4IjZnJmK+gWS3VSrLW/pXcbvq84jtCcbDKt/USKhBsb+VS94Em/k4K5J6N9AHkDUB0RQOW06A8HXlDVlwBE5HrgZCAu9JODMifjUFU8P5cX9N6sefU/41tBt1SGfKMhiKTK+Jn8ctbP5j8zYVowLHM2GOWzIK/m8sM2R/dvTjZy7LxlvK11kb0/hyDe2u/J9bKjvxMRSDkppqWbI639IoPAhUNA5GIDDyKB/z9wAeU7gMfXa17O0eYBGyPr7cDSIvk+JCJHA+uBf1TVjfEMIrIKWAWwYMGCkdd2NBSdjCN8A68BJYhD97Jks71BC90Kei0SF9bBopktFNaYaBohHRDWIbcXfIaCnR10bM23CHcNRxxSTpKkkyAZ+dzSt43fbvxf5jfOYcX85bxn7jJa61oqcsxaxRGHdKKOdDDRStjaD9uEzckmmlKNpBN1JELBDoeAiEuqqon/z+6EzPYg0Ye63aBuxridU6XMym+AX6lqv4h8EvgpcEw8k6peCVwJsGTJksrc4cUoMhmHIuRwyOGaOPRMF725LVbQxxjP9waJaaaEEA7kG5w+/Pag7EFiW1iGX0FhDcV0sMAG6W6KpmTj4PRieUuUEf1MucmS290SESK9uT7uf+0P3Nl+H1c9fz0/+dONHLHbIayYv5xDZx1Qcj/LANHWvqrmW/uIUufUxVr7Mc0IX5YkMgSEF0z8Mo6UI/SbgPmR9TYGOl0BUNWtkdUfA/++61UbAZHJODTTQS7bSc73yapPnw+9XqYigq6qwUQZPj5+fgo7P5oebPN8Dx8dmOZOo/kH9vdUC9Pz+/t4+IO3FRxfB6eH+5far8i+XtF6lai36qA84V9OvUHug7ER1lDk4qKXpDHRMCitmLAOFtjBwmrENTUiYa026hNpTph/NCfMP5o/d27irvb7+Z9ND/HgG6uZnZ7B8W1Hcfy8o9ijYfZEV3VSICIFrf2cnyto7YeRPAWt/SpABiZ/KJFBJIFxxxyLEfjHgTNV9ZlInjmq+lqwfApwgaoeMVS5S5Ys0dWrV4+4wvc/+h/89sXb8FE8VbxA1HL5dfBQfMAT4ymL/oXbfExeI8ZhukbymPKi62P3CFJ5HMTMxCSCgxMsm3WXgWVHnMh2KZgMu3A/B0dcXBEccQvzBduSbtDyLCrCMQEtyDM4b2HrdfII62Qg6+d49I0nubP9Pp7Ysg6AQ2a+jRXzl3PkboeScpPDlGAphqrS72XIeTk0aO231DXRkKwvbO17vZBsgfTojKuIrFHVJSPZZ1iTo6o5ETkXuBsTXnmNqj4jIl8HVqvq7cBnReQkIAdsA1aOuPZl8kbnRp7u34KjioMZB8MNll3AVXBRXCClihOs5/OpBvmC/VXzywn1g3zgBGXk91dTvoMObNfg+NHlSF3CY+U/B9VVC49X7Lix7YXlFdZhoI4Tg5eehjetjdy0ueRa28hNm43XMo/ctHlo3eSfv7ZWSDoJjppzGEfNOYw3e7dyT/v93N3+AN9a+0Nakk0cO++drGhbzl7NbRNd1UlF2Non0trf2redzb3bcEQG4vbxSI6zLR22RT9WjLZFD6C+TzbbiZfZSS6znb5sFxnPp199sgRTYaiYYBqRYEIM0wodvnAFNOhEUcA3c5WqH0n3w4oAisTTgn2lIL/my5aCsrXgmBIvh+JpZrl0vaTgHDS/b6n0fL0iZYf1K3p+8fy+h9u9mcSOV0l0tON2by74Wr36ViP6rfPITWsjN20e3rR55Frb0FTjCK6+ZSzw1Gftlme4s/0+HnnjCXLqse+0vVkx/2iWz1lKQ6J+oqs4qSlo7ft97DZtL6a3Lh5VWaNp0U9KoR+Elwmm3duBn+sh52XxcMmJS7+XMX+5DFnN5o0AopFZkco0ApaykWwf7s7XSOxoJ7GjHbdjE4kdm8xy95aCvF79dLxpcwMDYJ4IvFazrCk7W9V409G/k3tffZg72+/jL12vknbrWD5nKSe0HW3DNCtAb/8OWhr3YPaM/Ua1/9QV+ij5t1uDMWlQwvHffQTPNyNA5tSjP9dvjcAEYIyAafkndmzCDQxAYsemokYgN21eIPzzgr82vGnzrBEYY1SV5zte5K72+/j9a4/R5/WzoHEuJ8w/2oZp7gJW6CvNoBmdwnlYU4NmvPHVL2kEcuFMUDEjYD5rf+S78USyvbg7Xh0Q/tAIdGzC7dlakNdrmDHgAgrcQbnWwAgkrauhkvTkern/tT9wV/t9PNfxIglxOXL3Qzmh7WgbpjlCrNCPJZEQTDIdhS9OOXVDvqYcNwKZXIY+r7/ACIThVdYIjB3GCAQuoI72geUd7bg92wryGiNQ2BcQLlsjsGu80tnO3e3387tND7Ez22XDNEeIFfrxZAgXj5nlvsxiRmgEnGBQM2sEKkveCATuoMSOAUMw2AjMzHcKewXuoLnWCIyAjJfl0Tef5K72+3hii4m2tmGaw2OFfqIYgYtnRMWq5qf589SnP9dvjICXJedngzzWCIw1kukp6AdI7NiEG/YP9G4vyOs1ziroB8i7g1rmoqOYd2Cq8EbvFu5pf4B72h/gzb6tNkxzCKzQVwPFXDwQDEQ0tItnZIcpbgQyXo5s8BavyMB8r9YIjA2S6Y4I/6sDUUI7Xi1hBAIXUD5M1EQJhbHTUx1PfZ7c8gx32TDNklihr0Yq5OIZCcWMQL+foT+XHWQEnKAvwBqByiP9XZEO4Uin8M5NuL0dBXm9xtlBP8Dc4GkgjBKaukagVJjmirbl7Ne695QN07RCX+2MkYtnRFUIjICZKNyzRmCCKDQC7UHfwKu4O9px+3bk8ymC1zS7sC+gNVhumQeJ1ASexfigqjzX8SJ3x8I0V8xfzrFz3znlwjSt0E8mBrl4+shPWlJBF8/IqjTYCGT8LH25DFk/E+QyM11ZIzB2SH+XEf6dA30Bxii04/btzOczRmC3gZfFIpFBuZa5NWkESoVprmhbziGz9p8SYZpW6CczJV08dVUxyXA4FrtxCXlkgjeG40ZA1cd1XGsExgjp6yyMCgoMQqJjE05/zAg071b4jsC0eYFLaI5xHU5yioVpntB2NMe3HcXu9bMmunpjhhX6WiHv4gnHwx9/F89IGMoI5DSbn/PWGoGxRfp2FvYFRKKEnP7OfD4VJ3gSGIgKyhuBljkwycIai4VpHjprf05oO7omwzSt0Ncig2a4mngXz0iIG4Gsn6Uv1z/ICKCKOIKDQDDcsSA4IgiCBGmW0SF9O4IXxQrfEUjsaMfp78rnC41Avi+gdT7Z2fuQnbn3pBgyIgzTvLv9fjb3baMl2cR75i3jhLajayZM0wr9VKDKXTwjIW4Ecn4uP+FKzs8Fk5N4eL6i6g8MJVFAYOg0+E/McK/mH4g4+XUn/+lM2YiNQagi/TvzBmDAJRQYgUy3yYbgtbaRmbWY3OxFZGbtQ3b2IjQ9bYJPoDjFwjT3a92bE9omf5jmlBf6bDZLe3s7fX19E1Kn8UcLhgMmOqM8NSZkAumUy7zZjbiuoGh+xq6BZUXRwFiYN44938x6ZQyHyeOpMSLFDmKijjBfZdRoRI0E5J8wwm01iSpOz1aSmzeQ3LIh/5nofCOfJde0O9nZi8nOWmRa/rMX4zfMrKonzY7+nfzPqw9z18b7+Eu3CdN895ylnDBJwzSnvNC//PLLNDc3M3PmzEl38XaZgrHgPWpN9FWVrdu207lzOwvnVqYV6atvpocMpmwcMBzBtI/4+HlD4eH75qnCDFtROO1j/H5TQIJB7EJEBrumBPJPGJPFaEjfDpKbXygU/452M1cBZsTQAvGftRivZc6Ei38YpnlX+33cF4ZpNs1lRdvkCtOc8kL/3HPPse+++06KH8uYo1HRj7ZeJ5d7J4qq8vz6Dey314yJrkoBobGIPmEMGBHyaeYJY2SuKTPEhRS4poDIk0V1uKYk00Ny64uR1v96Etv/jPhmEms/1Uh21uLAAJjPXOt8mKAO+Z5cL/e99hh3bbyf53dMrjDNiRD66pm9NsCKfIBI8OatG2nte+Rnj9cgzyRq7Q8IXnURCi0CLrsmXMWfMIq7pnw/eNIIJlvP+R6e+niaGeSaUhTJG3nj8lPRAvdTvtM70vld7lOGphrIzDmQzJwDBxJzGZLbXh5o+W9eT+O62xDPhOP6iTpyM/cuEP/sjL3GJfSzIVHPifPfzYnz380rne3c1X4f/7PpYR54/XF2S880o2nWeJjmSKi6Fv1++43Oyk0ZJrmL57nn17Pfwupq0VcrxZ8wAoMxjGvK1+AJBA/fV9KJFMlKhCn6HontfyG5eT3JLS+Q3LKe5OYXcLI9ps5OgtyMvchEWv+5WXuPy6igGS/LI28+wd3t90fCNA9gRdvRHLHbIVUTpmlb9BNMR0cHv/zlL/n0pz894n3f+9738stf/pLW1tZdrkdTUxNdXV3FN4ateHGARE26eCwGEcHdxfGUVJWebC+be7bS2d9NXSK1a4LnuORmLiQ3cyG9nBAcxMfd+ZoR/81G/NOvPEzj83eazQi56QsiPv9FZGctRtPNu3RucVJukuVzlrJ8ztKCMM1vrr2caclmjp33zpoK0xwJtkUf4ZVXXuH9738/69atG7Qtl8uRSIyPXRxS6IciP+G4P2IXz3idn23RTwxRwe/z+kkn6sa2hauK072F5Ob1pDZvILFlA6nNGwomjc+1zAlE30T7mIifyt4bnvo8sWUdd7ffXxCmuaJtOcvnLKU+Mf5DT9sWfYSv/eYZnn115/AZR8Db5rbwbx/Yv+T2Cy+8kBdffJGDDz6Y4447jve97318+ctfZvr06Tz//POsX7+eD37wg2zcuJG+vj7OO+88Vq1aBcBee+3F6tWr6erq4sQTT+Rd73oXDz/8MPPmzeO2226jvr6eF198kXPOOYfNmzfT0NDAVVddxb777svLL7/MmWeeSVdXFyeffHLJ+l166aVcc801AHz84x/nc5/7HK+88krx46XTRF08N950I1/7xrdwXZdpLdO4//f/w7U//Rn/75Zb6erqxvM8fvubW/nMef/I6jVrEBH+7ctf4kOnnlLRa2CZGESExlQDDcl6enN9vNm9hZ39XWMn+CL4TbPpb5pN/8Jl+WSnt2NQuGf9Sw/kt3sNMwt9/rMW4zXvPuqIH1ccDpv9dg6b/faCMM3/WHcNVzx3He8ORtPcdxKGaY6EqhX6ieDiiy9m3bp1rF27FoDf//73PPHEE6xbt46FCxcCcM011zBjxgx6e3s57LDD+NCHPsTMmTMLytmwYQO/+tWvuOqqqzj99NO5+eabOeuss1i1ahU/+tGPWLx4MY899hif/vSnuffeeznvvPP41Kc+xcc+9jEuv/zyonVbs2YNP/nJT3jsscdQVZYuXcry5cuZPn16yeNFXTxfv+hi7r7zTubN3YOOjm0YN4/yxJNr+eOTq5kxYwYXXPivTJvWwtNrnwBg+/btRetimbyICA3Jevac1kZvrs+4dDLd1Lm76NIpE7++lf4Fh9G/4LCBOvV3DUT8BL7/ur/8AQk6pP265gLxz8xajNfaNuIXDFvrWvjQwhWcutcJPNvxAne338//vvYod7Xfz4KmuZzYtpxj5y1jWqqyLqVqoGqFfqiW93hy+OGH50Ue4Pvf/z633HILABs3bmTDhg2DhH7hwoUcfPDBALzjHe/glVdeoauri4cffpjTTjstn6+/30xq8tBDD3HzzTcD8NGPfpQLLrhgUD0efPBBTjnlFBobGwE49dRTeeCBBzjppJOKHi/OsmXLWPn3/8Dpp5/OqaecEoy543Dce45hxoxWwOd3997L9df9PL/P9OnTR/JVWSYRoeAvaJlHb66PLb1b2dnfRV0iRd04D5imdU1k5h5EZu5BA4m5fpJbXwpa/cb33/jH/4cEM7P5iXTg84+Ee07fC9zhJU1E2H/6Yvafvpiz9zszH6b5f5//FVf/6QaO3P1QTgzCNGtl2I6qFfpqIRRWMC383/3udzzyyCM0NDTw7ne/u+hbvHV1AxNNuK5Lb28vvu/T2tqaf1qIsyuPjcWOF+dHP/oRjz32GL/97W95x5IlrFmzBhyXxsZmM9haPpwv8PNPkigey66RF/xkG73ZXjZPoOAXkKgju/t+ZHeP+LG9HIntr5hon6Dl3/DcnTg50/BSJ0l25sJC18/MvYec+KVYmObvNj2UD9M8oe0ojm87mt3qZ5YsYzJghT5Cc3MznZ2dJbfv2LGD6dOn09DQwPPPP8+jjz5adtktLS0sXLiQG2+8kdNOOw1V5Y9//CMHHXQQy5Yt4/rrr+ess87iuuuuK7r/UUcdxcqVK7nwwgtRVW655RZ+/vOfF81bjBdffJGlS5eydOlS7rzzTjZu3Gg2SODeEYfjjjuey6+4iu/9x6WgHtu3b4206mujZWMpTX1E8Lf0bqOzv5tUIjmxgh/FTZCbtYjcrEX07rvCpKmP29FOcssLpDavNz7/Fx+g8dnfms3iBBE/kZe9Zi1C65oGFb9Xcxtn7/cR/n6f03nkzSe4a+N9/PyFW/nFC7dx6KwDOLFtOUfsfghJZ/LJ5uSr8Rgyc+ZMli1bxgEHHMCJJ57I+973voLtK1as4Ec/+hH77bcfb33rWzniiCNGVP51113Hpz71KS666CKy2SxnnHEGBx10EJdddhlnnnkm3/72t0t2xh566KGsXLmSww8/HDCdsYccckhRN00xzj//fDZs2ICqcuyxx3LQQQcNerr40pe+xDnnnMMBbz8I13X5t698hVNP/eBAFE8wfoxt7dc29cl65ifn5QV/Z38XKTdJuhqnRBQHb/oCvOkL6Ft8jElTxe16o6DTt27TkzSs/+/8brmWuUGkzz75sE+/vhUoDNN8vWcz92x6gLvbH+Citf8ZhGkuY0Xb0ezZPG8CTnh0lBVeKSIrgMsAF/ixql5cIt+HgJuAw1R1yKEpqzG80jIEFXpRy4ZXTj76cn1s6dlGV7anegW/DJyebYMHeNv5Wn671zg74vYxI3z6TbNBJB+medfG+3jkzSfx1GO/1kWc2Laco+ccPqIwzaoMrxQRF7gcOA5oBx4XkdtV9dlYvmbgPOCxkVTAMkkY9KJWMOLmoBe1bGu/1kgn0rS1zKUv18fW3u10ZrpIOpNP8P2GGfTvuZT+PZfm06Svk+TWF4KIHyP+dX9+NB/x46Wn5d0+R81ezBFvOYWtb/sov3vtEe7aeB+XrruaK567Lpj0/OiqDdMsx3VzOPCCqr4EICLXAycDz8byfQP4NnB+RWtoqU7ECfTcjb2o5QfLRPTe+vdrgXQizbzmOXnB39nfSdJNTshLR5VC081k5h1CZt4h+TTJ9pLY+tLAMA+bN9D01I2Ibwatm51sYO/Zi/i7mYt4cs4B/Ca7mf997RHuar+PPZvmsaLt6KoL0yxH6OcBGyPr7cDSaAYRORSYr6q/FZGSQi8iq4BVAAsWLBh5bS3ViQjgBoOwEXHzRAxA3tUTTLPoJCfdRCsWQyj4/bl+tvbVhuBH0WQ92T32J7tHJMTby5LY9krQ4WvEv/G533J0rp+jgc5EHb/dbT63yPYgTPPXHLnbIZw4/6+qIkxzlztjRcQBLgVWDpdXVa8ErgTjo9/VY1uqlLybByAm/uKCm4ZcN/kJV8QFJwGSnPAxzy3lU5eoY27THsxMT2dbXwc7+ztJuImaEfwC3CS52YvJzV48kOZ7JDragzj/DZyy5QVOb1/PC5rhluZGfpN7nAfeWMMckpzY/BaOn7+cGXMOKX2MMaQcod8EzI+stwVpIc3AAcDvA9/UHsDtInLScB2ylilE1MffMMek+Tkzn244kbrXw0AMv2ta/ZMwlG2qUZeoY07T7sxItw4IvuOSTqSr0l9dMRyX3Iw9yc3Yk959jjNpqkzrfJ1PbF7Px9/8Ew9te4bfZLdwDX/iJ888z5Gr+zjZS7H0HavgyPELPCnnV/Q4sFhEFmIE/gzgzHCjqu4A8oM+i8jvgc9bkbcMi5Mwf4kGqJseTKSeBc1Crte0+nNdA/5+SQQun4mZ7MIyNKHgz6yfzrbeDjr6d5B0ErUv+FFE8FrmmBm59l7OEmCJKm9sXc/vXr6bu7at4wK/n7M713POOFZrWMeRquaAc4G7geeAG1T1GRH5uoicNNYVrGZWrlzJTTfdBMADDzzA/vvvz8EHH1zwZmpHRwc//OEPR1X+e9/7Xjo6OipR1cmBiJm0ItEI6VnQtCc0LzKf9XNMup+FXKcxANku8zRQdP5Yy0SRclPs0bQbb2ndk6ZUE13ZbnqyvUzUSLkTjgi7z3orHznss1x7/I/48kFn854DPjquVSjruVhV7wDuiKV9pUTed+96tSYf1113HV/4wheCwcQGCIW+2Bj3ww0NfMcdd5TcNmUQB9w685cMohh8z7h8/EzQ6g9cPtbfX1Wk3BS7N85menoa2/t20NG/A1dc6qdSCz+GKw7vmPk2WtKt43rc6nWA3nkhvP50Zcvc40A4sei7Xnm6u7s5/fTTaW9vx/M8vvzlL7No0SL+6Z/+ia6uLmbNmsW1117LnDlz8vv8+Mc/5oYbbuDuu+/mzjvvLBjGYKyHPp6SOC449UA9pIKJxq2/v2oJBX9GupXtfTvY3t8x5QV/vLF3foy77rqLuXPn8tvfmrEyduzYwYknnshtt93G7Nmz+fWvf80Xv/jF/LjwYIYjePDBB3n/+9/Phz/84YLyxnroY0vAkP7+HvOX7SQfDWT9/eNO0k2yW+Osgha+iNCQqLeCP8ZUr9AP0/IeKw488ED++Z//mQsuuID3v//9TJ8+nXXr1nHccaZX3fO8gtb8aKjU0MeWIQj9/QQ+fzC+fD8buHx6jNtHg/4UJWj12/j+sSYq+B19O9nWtx3XsS38saR6hX6C2GeffXjiiSe44447+NKXvsQxxxzD/vvvzyOPPFLW/hs3buQDH/gAAGeffTYrVqwYlKdSQx9bRoj191cVSTfJ7MaZtKZb2NG/k629VvDHCiv0MV599VVmzJjBWWedRWtrKz/84Q/ZvHkzjzzyCEceeSTZbJb169ez//7FJ0aZP39+waiQW7duHbOhjy0VoKi/P2v+rL9/XEi6SWY1zKQ1PY2Ovh1s6+tAEOqT6Ql/o7RWsHdrjKeffprzzz8fx3FIJpNcccUVJBIJPvvZz7Jjxw5yuRyf+9znSgp9nLEe+tgyBoQuHOvvH1cSTsIK/hhR1jDFY4EdpnhqUjPXuKi/P0fg7I+IvxWo0ZLzc+zo28nWvu01JfhVOUyxxWIpgvX3jzkJJ8HMhhm0pqflffiK0pCsrwnBH0+s0FsslWJIf3+fEX/r7x8xruMyo3460+pa2JnpZEvPNiv4I8TeYRbLWFLg758x4O/3M+AF4/lYf39ZuI7L9HQrLalmK/gjxAq9xTKehPH9bgqSTcDsAX+/1z8g/tqL9fcXJy74W3u34/s+9ck0rmMNZDGs0FssE03U30+LSSvw93eZ0TzzM3c5gfAnprS/v6jgZ63gF8MKvcVSjVh/f9mEgj+troXO/i429261gh/DPgvuAnaY4gFuvfVWnn02Po2wpaJEff2N880Qzo0LoX4upFoAf2D45lyXMQjqTXStxw1HHKalW3hL657s3jibjJels78bz58630EprNBXiHCY4rVr1xaMKjmU0OdyuSHLvOOOO2htba1kNYuiqvi+X3K9HKzQTwChvz/ZBOnZ0LTXwPj96T0i4/d3BWP4dxtXUI2PCx8K/sLWBcxp2s0KPlXsuvn2H77N89uer2iZ+87YlwsOv6Dk9mJDFP/1X/81a9asmRTDFL/xxhucffbZvPTSSwBcccUVvPOd7+TSSy/Nj7b58Y9/nM997nO88sornHDCCSxdupQ1a9bwwx/+kFWrVuXX77jjDm644QZuuOEG+vv7OeWUU/ja174GwM9+9jO+853vICK8/e1v51Of+hS333479913HxdddBE333wze++9d2UummVkFPX35wZcPl7wZm9+svbadfk44tBS10xTqpGuTDebe7aSy/ZRn6wjUYPnOxRT62yHodgQxdlsls985jOTYpjiz372syxfvpxbbrkFz/Po6upizZo1/OQnP+Gxxx5DVVm6dCnLly9n+vTpbNiwgZ/+9KccccQRvPLKKwXr99xzDxs2bOAPf/gDqspJJ53E/fffz8yZM7nooot4+OGHmTVrFtu2bWPGjBmcdNJJRc/fUgXkh3CuB4oN6RBO2ajGUIgLTqpmonzigr+lZxu92f4pJfhVe5ZDtbzHivgQxUcddRTr1q2bNMMU33vvvfzsZz8DzAiX06ZN48EHH+SUU07Jj5h56qmn8sADD3DSSSex5557FoytE12/5557uOeeezjkEDNrfVdXFxs2bOCpp57itNNOY9YsM03wjBkzdum7sEwAg4ZwDkM8w4lbekzLX73IW72TP8onFPzmVFO+hT9VBL+2z26ExIcoPvbYYznllFNqdpjiaD3i66rKF77wBT75yU8W5PnBD36wy8e1VCHigJs2f4Nm7QqjfLqDzBrE9qcm5YtdIkJzXVOBS6c32086kSLpJie6emNCbTybVYhXX32VhoYGzjrrLM4//3yeeOIJ3vrWt+aHKQbIZrM888wzJcsIhyleu3YtZ599Ns3NzeM2TPGxxx7LFVdcAZgnjx07dnDUUUdx66230tPTQ3d3N7fccgtHHXXUsGWdcMIJXHPNNXR1dQGwadMm3nzzTY455hhuvPFGtm7dCsC2bdsAhj1PyyQkP2NXGOWzGBr3hPp5kGgunKg91x1M1D55OnpDwV/YuoC5TbvjqbKzv4usl53oqlUc26KPUGyI4lQqxU033TQphim+7LLLWLVqFVdffTWu63LFFVdw5JFHsnLlSg4//HDA9Ccccsghw85Qdfzxx/Pcc89x5JFHAtDU1MQvfvEL9t9/f774xS+yfPlyXNflkEMO4dprr+WMM87gE5/4BN///ve56aabbGdsLSISGcitCdit+ItdYUinBH0DTnW3kqMt/O5sD5t7ttHZ311TLXw7TLFlXLHXuMZRNcM1+xkj+rlu8PuDN3qJuHyq15mgqvRke9ncs5V+L0NdIkWqgoJvhym2WCyTGxEzFLOTDDp6Z8XG8gnCOzVLoPxBR2/1DN8sIjSmGmhI1ucFf2d/F+lEXUUFfzyxQm+xWMaW4WL748M5iBsYi4mVp1oSfCv0Fotl/InG9kena8wP39wFub6gc1cGhnueAJdPVPB7c31s7tlKZ6abOreyLp2xxAq9xWKZeIoN3+x7xsUTxvbnupnIETxFhIZkPQta5tGb62NLr2nh1yVS1LmpcanDaLFCb7FYqhPHBdxYbH8wgmeu18T152P7ibzRO7ax/XnBT7bRm+1l8yQQ/LKeg0RkhYj8SUReEJELi2w/W0SeFpG1IvKgiLyt8lW1WCxTnnAEz/RMaFwQie2fC4mmwYO4jXFsf32yngUtbezZMo+EuHT2d9PvZcbseKNlWKEXERe4HDgReBvwN0WE/JeqeqCqHgz8O3BppSs6HlTLkMJNTU0VKSfKeI0uuSvfocUyYsLY/mQT1O8OzW+Bpr2hYQHUzTauIK8nGL650zwJ+EOPGjsa6pP1zG+Zx4KWuSTEZWd/F325/oofZ7SU06I/HHhBVV9S1QxwPXByNIOq7oysNjIwNN6kYjIMKTxaRiP0w51zMazQWyYcxw06eVuhYV4wdPNCaGwLXEBqRL9g3P6RDctdilDw95rWRspJVo3gl+OjnwdsjKy3A0vjmUTkHOCfgBRwTLGCRGQVsApgwYIFQx709W99i/7nKjtMcd1++7LHv/5rye1jPaTwiy++yDnnnMPmzZtpaGjgqquuYt999+Xll1/mzDPPpKuri5NPPrlk/UoNNzzcEMYPP/zwoGGE7733Xq688koymQyLFi3i5z//OQ0NDaxcuZJ0Os2TTz7JsmXLOOecc/jIRz5Cd3c3J598Mt/73vfywyJccsklg4Yxjn+Hl1xySSUuncUyekrG9mfAywQunt5IbL9jIoJ2IbY/nUjT1jKXvlwfW3u305npIukkSSfqht95DKhYrJKqXq6qewMXAF8qkedKVV2iqktmz55dqUNXjIsvvpi9996btWvX5gXqiSee4LLLLmP9+vWAGVJ4zZo1rF69mu9///v5MV+ibNiwgXPOOYdnnnmG1tZWbr75ZgBWrVrFD37wA9asWcN3vvMdPv3pTwNw3nnn8alPfYqnn3665MiY0eGGH330Ua666iqefPLJIY8X8s53vpOTTjqJSy65hLVr17L33ntz6qmn8vjjj/PUU0+x3377cfXVV+fzt7e38/DDD3PppZdy3nnncd555/H000/T1taWzxMdxnjt2rWsWbOG+++/v+h3aLFUHeEgbqkWaJgTcfm0Qd1M06EbunxyXcYQjMLlk06kmdc8hz1b2qhzU+zs7yQzAT78clr0m4D5kfW2IK0U1wNX7EqlgCFb3uNJpYYU7urq4uGHH+a0007L5+vvN490Dz30UF6cP/rRj3LBBYOHaB5quOFyhjCOs27dOr70pS/R0dFBV1cXJ5xwQn7baaedhuuayIVHHnmEW2+9FYAzzzyTz3/+80DpYYyHe1KzWKqWfGx/w+DY/lyPifDJBSPLKiOK7Q8Fvz/Xz9bu18Z9WORyjvY4sFhEFmIE/gzgzGgGEVmsqhuC1fcBG6gRKjWksO/7tLa25icgiSO7EAs8miGMV65cya233spBBx3Etddey+9///v8tvjwxcUoNYxxOUbGYpkUDIrtJxbb3x0M5+Bh3uh1BsS/BHWJOuY27Q7JlvE5h4BhTZGq5oBzgbuB54AbVPUZEfm6iJwUZDtXRJ4RkbUYP/3fjlWFx5KxHFK4paWFhQsXcuONNwJGKJ966ikAli1bxvXXXw9QMA1hlNEONxwSP7fOzk7mzJlDNpsteUyAI444Iv+0EdYRSg9jbIcrttQ0TiSuv2EutCwybp/GeZCaboxDPsKneiZoL8tHr6p3qOo+qrq3qn4zSPuKqt4eLJ+nqvur6sGq+leqWnrA9iomOqTw+eefP2j7ihUryOVy7Lffflx44YUjHlL4uuuu4+qrr+aggw5i//3357bbbgPM8MKXX345Bx54IJs2FfeKHXroofnhhpcuXZofbrhczjjjDC655BIOOeQQXnzxRb7xjW+wdOlSli1bxr777ltyv+9973tceumlvP3tb+eFF15g2jTz4srxxx/PmWeeyZFHHsmBBx7Ihz/8YTo7O4f9Di2WmiPs5M3H9i8yE7XXzykxQXvlwzuHww5TbBmSnp4e6uvrERGuv/56fvWrX+UN1Giw19gyJYlP0J5ohFTrqIqywxRbKs6aNWs499xzUVVaW1sLJkW3WCxlEp+gfZyxQm8ZkqOOOirfl2CxWCYnVTfNy0S5kixjj722FsvEUFVCn06n2bp1qxWEGkRV2bp1K+l0eqKrYrFMOarKddPW1kZ7ezubN2+e6KpYxoB0Ol3wdq3FYhkfqkrok8lkwVuoFovFYtl1qsp1Y7FYLJbKY4XeYrFYahwr9BaLxVLjTNibsSKyGfjzKHefBWypYHUslcFel+rDXpPqZFeuy56qOqJx3idM6HcFEVk90leALWOPvS7Vh70m1cl4XxfrurFYLJYaxwq9xWKx1DiTVeivnOgKWIpir0v1Ya9JdTKu12VS+ugtFovFUj6TtUVvsVgsljKxQm+xWCw1zoQLvYioiHw3sv55EfnqCPZfKSL/WST970XkaRH5o4isE5GTK1RlSwwROS/4jp8Rkc9NdH0sICJpEfmDiDwVXJevTXSdLCAi14jImyKybjyPO+FCD/QDp4rIrEoVKCJtwBeBd6nq24EjgD9WqnzLACJyAPAJ4HDgIOD9IrJoYmtlwfyujlHVg4CDgRUiMrJJji1jwbXAivE+aDUIfQ7TA/2P8Q0ispeI3Bu0yv9HRBaUWeZuQCfQBaCqXar6csVqbImyH/CYqvaoag64Dzh1gus05VFDV7CaDP5s5MUEo6r3A9vG+7jVIPQAlwMfEZFpsfQfAD8NWuXXAd8vs7yngDeAl0XkJyLygcpV1RJjHXCUiMwUkQbgvcD8Ca6TBRARV0TWAm8C/62qj01wlSwTRFUIvaruBH4GfDa26Ujgl8Hyz4F3lVmeh3k8+jCwHviPkfj9LeWjqs8B3wbuAe4C1gLeRNbJYlBVT1UPBtqAwwM3m2UKUhVCH/A94B+AxkoUFjy6/kFV/w9wBvChSpRrGYyqXq2q71DVo4HtGONqqRJUtQP4XybAN2ypDqpG6FV1G3ADRuxDHsaINMBHgAfKKUtE5orIoZGkgxn9SJmWYRCR3YLPBRj//C+H3sMy1ojIbBFpDZbrgeOA5ye0UpYJo6qmEgS+C5wbWf8M8BMROR/YDPxdif1WisgHI+vLgO+IyFygL9j37MpX1xJws4jMBLLAOUEL0jKxzAF+KiIupkF3g6r+1wTXacojIr8C3g3MEpF24N9U9eoxP64dAsFisVhqm6px3VgsFotlbLBCb7FYLDWOFXqLxWKpcazQWywWS41jhd5isVhqHCv0FovFUuNYobdYLJYa5/8DjFfB33v/JWEAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 71,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635998581695
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "azureml_py38_tensorflow",
      "language": "python",
      "display_name": "Python 3.8 - Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "azureml_py38_tensorflow"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}